"""
Enterprise AI Assistant - Run Script
EndÃ¼stri StandartlarÄ±nda Kurumsal AI Ã‡Ã¶zÃ¼mÃ¼

UygulamayÄ± baÅŸlatmak iÃ§in ana script.
"""

import subprocess
import sys
import os
import time
import webbrowser
import socket
from pathlib import Path

# Add project root to path
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# Default ports
DEFAULT_API_PORT = 8001
DEFAULT_FRONTEND_PORT = 8501


def find_free_port(start_port: int, max_attempts: int = 10) -> int:
    """BoÅŸ port bul. MeÅŸgulse bir sonrakini dene."""
    port = start_port
    for _ in range(max_attempts):
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('localhost', port))
                return port
        except OSError:
            print(f"   âš ï¸ Port {port} meÅŸgul, {port + 1} deneniyor...")
            port += 1
    raise RuntimeError(f"BoÅŸ port bulunamadÄ± ({start_port}-{start_port + max_attempts})")


def kill_process_on_port(port: int) -> bool:
    """Belirtilen porttaki iÅŸlemi sonlandÄ±r."""
    try:
        if sys.platform == 'win32':
            # Windows iÃ§in
            result = subprocess.run(
                ['netstat', '-ano'],
                capture_output=True,
                text=True
            )
            for line in result.stdout.split('\n'):
                if f':{port}' in line and 'LISTENING' in line:
                    parts = line.split()
                    pid = parts[-1]
                    subprocess.run(['taskkill', '/F', '/PID', pid], capture_output=True)
                    return True
        else:
            # Linux/Mac iÃ§in
            subprocess.run(['fuser', '-k', f'{port}/tcp'], capture_output=True)
            return True
    except Exception:
        pass
    return False


def check_ollama():
    """Ollama'nÄ±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et."""
    try:
        import requests
        response = requests.get("http://localhost:11434/api/version", timeout=5)
        return response.status_code == 200
    except:
        return False


def check_models():
    """Gerekli modellerin yÃ¼klÃ¼ olup olmadÄ±ÄŸÄ±nÄ± kontrol et."""
    try:
        import ollama
        client = ollama.Client()
        result = client.list()
        
        # Handle both old (dict) and new (object) API formats
        if hasattr(result, 'models'):
            # New API: result.models is a list of Model objects
            model_names = [m.model for m in result.models]
        elif isinstance(result, dict):
            # Old API: result is a dict with 'models' key
            model_list = result.get("models", [])
            model_names = []
            for m in model_list:
                if isinstance(m, dict):
                    model_names.append(m.get("name", m.get("model", "")))
                else:
                    model_names.append(str(m))
        else:
            model_names = []
        
        required = ["qwen", "nomic-embed-text"]  # qwen3-vl veya qwen2.5 olabilir
        missing = []
        
        for req in required:
            if not any(req in m.lower() for m in model_names):
                missing.append(req)
        
        return missing
    except Exception as e:
        print(f"Model kontrolÃ¼ hatasÄ±: {e}")
        return []  # Hata olursa model indirmeye zorlamayalÄ±m


def pull_models(models):
    """Eksik modelleri indir."""
    import ollama
    client = ollama.Client()
    
    for model in models:
        print(f"\nğŸ“¥ {model} indiriliyor...")
        try:
            client.pull(model)
            print(f"âœ… {model} indirildi")
        except Exception as e:
            print(f"âŒ {model} indirilemedi: {e}")


def run_api(port: int):
    """API sunucusunu baÅŸlat."""
    env = os.environ.copy()
    env['API_PORT'] = str(port)
    
    return subprocess.Popen(
        [sys.executable, "-m", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", str(port)],
        cwd=str(PROJECT_ROOT),
        env=env,
    )


def run_frontend(port: int, api_port: int):
    """Streamlit frontend'i baÅŸlat."""
    frontend_path = PROJECT_ROOT / "frontend" / "app.py"
    
    env = os.environ.copy()
    env['API_BASE_URL'] = f'http://localhost:{api_port}'
    env['STREAMLIT_SERVER_PORT'] = str(port)
    
    return subprocess.Popen(
        [sys.executable, "-m", "streamlit", "run", str(frontend_path), 
         "--server.port", str(port),
         "--server.headless", "true"],
        cwd=str(PROJECT_ROOT),
        env=env,
    )


def main():
    """Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu."""
    print("=" * 60)
    print("ğŸ¤– Enterprise AI Assistant")
    print("   EndÃ¼stri StandartlarÄ±nda Kurumsal AI Ã‡Ã¶zÃ¼mÃ¼")
    print("=" * 60)
    
    # Step 1: Check Ollama
    print("\nğŸ“¡ Ollama kontrol ediliyor...")
    if not check_ollama():
        print("âŒ Ollama Ã§alÄ±ÅŸmÄ±yor!")
        print("   LÃ¼tfen Ã¶nce Ollama'yÄ± baÅŸlatÄ±n: https://ollama.ai")
        print("   Windows'ta: Ollama uygulamasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n")
        return
    print("âœ… Ollama aktif")
    
    # Step 2: Check models
    print("\nğŸ” Modeller kontrol ediliyor...")
    missing_models = check_models()
    
    if missing_models:
        print(f"âš ï¸ Eksik modeller: {', '.join(missing_models)}")
        response = input("Ä°ndirmek ister misiniz? (e/h): ")
        if response.lower() == 'e':
            pull_models(missing_models)
        else:
            print("âš ï¸ Modeller olmadan sistem dÃ¼zgÃ¼n Ã§alÄ±ÅŸmayabilir")
    else:
        print("âœ… TÃ¼m modeller mevcut")
    
    # Step 3: Create directories
    print("\nğŸ“ KlasÃ¶rler kontrol ediliyor...")
    from core.config import settings
    settings.ensure_directories()
    print("âœ… KlasÃ¶rler hazÄ±r")
    
    # Step 4: Find free ports
    print("\nğŸ”Œ Portlar kontrol ediliyor...")
    
    api_port = find_free_port(DEFAULT_API_PORT)
    print(f"   âœ… API port: {api_port}")
    
    frontend_port = find_free_port(DEFAULT_FRONTEND_PORT)
    print(f"   âœ… Frontend port: {frontend_port}")
    
    # Step 5: Start services
    print("\nğŸš€ Servisler baÅŸlatÄ±lÄ±yor...")
    
    try:
        # Start API
        print(f"   ğŸ“¡ API baÅŸlatÄ±lÄ±yor (port {api_port})...")
        api_process = run_api(api_port)
        time.sleep(3)
        
        # Start Frontend
        print(f"   ğŸŒ Frontend baÅŸlatÄ±lÄ±yor (port {frontend_port})...")
        frontend_process = run_frontend(frontend_port, api_port)
        time.sleep(3)
        
        print("\n" + "=" * 60)
        print("âœ… Enterprise AI Assistant baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
        print("=" * 60)
        print("\nğŸ“ EriÅŸim Adresleri:")
        print(f"   ğŸŒ Frontend: http://localhost:{frontend_port}")
        print(f"   ğŸ“¡ API:      http://localhost:{api_port}")
        print(f"   ğŸ“š API Docs: http://localhost:{api_port}/docs")
        print("\nâŒ¨ï¸  Durdurmak iÃ§in Ctrl+C")
        print("=" * 60)
        
        # Open browser
        time.sleep(2)
        webbrowser.open(f"http://localhost:{frontend_port}")
        
        # Wait for processes
        api_process.wait()
        frontend_process.wait()
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Servisler durduruluyor...")
        api_process.terminate()
        frontend_process.terminate()
        print("âœ… GÃ¼le gÃ¼le!")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")


if __name__ == "__main__":
    main()
