"""
StatisticsAgent - Premium Ä°statistik Analiz AjanÄ±
==================================================

GÃ¶revler:
1. Ä°statistiksel veri Ã§Ä±karma ve analiz
2. Veri tutarlÄ±lÄ±k kontrolÃ¼
3. Ä°statistiksel yanlÄ±ÅŸlÄ±k tespiti
4. GÃ¶rselleÅŸtirme Ã¶nerileri
5. Ã–zet istatistikler
6. KarÅŸÄ±laÅŸtÄ±rmalÄ± analiz
"""

import asyncio
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime

from core.llm_manager import llm_manager


class StatisticType(str, Enum):
    """Ä°statistik tÃ¼rleri."""
    PERCENTAGE = "percentage"
    COUNT = "count"
    MEAN = "mean"
    MEDIAN = "median"
    RANGE = "range"
    RATIO = "ratio"
    GROWTH_RATE = "growth_rate"
    CORRELATION = "correlation"
    P_VALUE = "p_value"
    CONFIDENCE_INTERVAL = "confidence_interval"


class VisualizationType(str, Enum):
    """GÃ¶rselleÅŸtirme tÃ¼rleri."""
    BAR_CHART = "bar_chart"
    LINE_CHART = "line_chart"
    PIE_CHART = "pie_chart"
    SCATTER_PLOT = "scatter_plot"
    HISTOGRAM = "histogram"
    BOX_PLOT = "box_plot"
    HEATMAP = "heatmap"
    TABLE = "table"


@dataclass
class ExtractedStatistic:
    """Ã‡Ä±karÄ±lan istatistik."""
    value: str
    type: StatisticType
    context: str  # Hangi baÄŸlamda kullanÄ±lmÄ±ÅŸ
    source_sentence: str
    has_source: bool
    source_citation: Optional[str] = None
    year: Optional[int] = None
    unit: Optional[str] = None
    
    # DoÄŸrulama
    is_valid: bool = True
    issues: List[str] = field(default_factory=list)


@dataclass
class StatisticalError:
    """Ä°statistiksel hata."""
    error_type: str
    description: str
    location: str
    severity: str  # "low", "medium", "high", "critical"
    suggestion: str


@dataclass
class VisualizationRecommendation:
    """GÃ¶rselleÅŸtirme Ã¶nerisi."""
    chart_type: VisualizationType
    title: str
    data_points: List[Dict[str, Any]]
    reason: str
    priority: int


@dataclass
class StatisticsReport:
    """Ä°statistik raporu."""
    total_statistics: int
    statistics: List[ExtractedStatistic]
    errors: List[StatisticalError]
    visualization_recommendations: List[VisualizationRecommendation]
    summary: Dict[str, Any]
    
    def to_markdown(self) -> str:
        """Markdown formatÄ±nda rapor."""
        lines = [
            "# ğŸ“Š Ä°statistik Analiz Raporu",
            "",
            f"**Toplam Ä°statistik:** {self.total_statistics}",
            f"**Tespit Edilen Hata:** {len(self.errors)}",
            ""
        ]
        
        if self.errors:
            lines.extend([
                "## âš ï¸ Potansiyel Hatalar",
                ""
            ])
            for error in self.errors:
                lines.append(f"- **{error.error_type}** ({error.severity}): {error.description}")
            lines.append("")
        
        if self.visualization_recommendations:
            lines.extend([
                "## ğŸ“ˆ GÃ¶rselleÅŸtirme Ã–nerileri",
                ""
            ])
            for rec in self.visualization_recommendations:
                lines.append(f"- **{rec.chart_type.value}**: {rec.title}")
        
        return "\n".join(lines)


class StatisticsAgent:
    """
    Premium Ä°statistik Analiz AjanÄ±
    
    Ä°Ã§erikteki istatistikleri analiz eder, doÄŸrular ve gÃ¶rselleÅŸtirme Ã¶nerir.
    """
    
    def __init__(self, global_state: Optional[Any] = None):
        self.global_state = global_state
        
        # Ä°statistik desenleri
        self.patterns = {
            "percentage": r'%\s*(\d+(?:[.,]\d+)?)|(\d+(?:[.,]\d+)?)\s*%',
            "number": r'\b(\d{1,3}(?:[.,]\d{3})*(?:[.,]\d+)?)\s*(milyon|milyar|bin|trilyon|million|billion|thousand)?',
            "ratio": r'(\d+(?:[.,]\d+)?)\s*[:/]\s*(\d+(?:[.,]\d+)?)',
            "range": r'(\d+(?:[.,]\d+)?)\s*[-â€“]\s*(\d+(?:[.,]\d+)?)',
            "p_value": r'p\s*[<=<>]\s*(\d+[.,]\d+)|p\s*=\s*(\d+[.,]\d+)',
            "confidence": r'%\s*(\d+)\s*(?:gÃ¼ven|CI|confidence)',
            "year": r'\b(19|20)\d{2}\b'
        }
    
    async def analyze_document(
        self,
        content: str
    ) -> StatisticsReport:
        """
        DokÃ¼manÄ± istatistiksel aÃ§Ä±dan analiz et.
        
        Args:
            content: DokÃ¼man iÃ§eriÄŸi
            
        Returns:
            Ä°statistik raporu
        """
        # Ä°statistikleri Ã§Ä±kar
        statistics = await self.extract_statistics(content)
        
        # HatalarÄ± tespit et
        errors = await self.detect_errors(content, statistics)
        
        # GÃ¶rselleÅŸtirme Ã¶ner
        recommendations = await self.recommend_visualizations(statistics)
        
        # Ã–zet oluÅŸtur
        summary = self._create_summary(statistics)
        
        return StatisticsReport(
            total_statistics=len(statistics),
            statistics=statistics,
            errors=errors,
            visualization_recommendations=recommendations,
            summary=summary
        )
    
    async def extract_statistics(
        self,
        content: str
    ) -> List[ExtractedStatistic]:
        """
        Ä°Ã§erikten istatistikleri Ã§Ä±kar.
        
        Args:
            content: DokÃ¼man iÃ§eriÄŸi
            
        Returns:
            Ã‡Ä±karÄ±lan istatistikler
        """
        statistics = []
        
        # CÃ¼mlelere bÃ¶l
        sentences = re.split(r'[.!?]\s+', content)
        
        for sentence in sentences:
            # YÃ¼zdeler
            for match in re.finditer(self.patterns["percentage"], sentence):
                value = match.group(1) or match.group(2)
                if value:
                    stat = ExtractedStatistic(
                        value=f"%{value}",
                        type=StatisticType.PERCENTAGE,
                        context=self._extract_context(sentence),
                        source_sentence=sentence.strip(),
                        has_source=self._has_citation(sentence)
                    )
                    self._validate_percentage(stat)
                    statistics.append(stat)
            
            # p-deÄŸerleri
            for match in re.finditer(self.patterns["p_value"], sentence, re.IGNORECASE):
                value = match.group(1) or match.group(2)
                if value:
                    stat = ExtractedStatistic(
                        value=f"p={value}",
                        type=StatisticType.P_VALUE,
                        context=self._extract_context(sentence),
                        source_sentence=sentence.strip(),
                        has_source=self._has_citation(sentence)
                    )
                    self._validate_p_value(stat)
                    statistics.append(stat)
            
            # BÃ¼yÃ¼k sayÄ±lar
            for match in re.finditer(self.patterns["number"], sentence):
                value = match.group(1)
                unit = match.group(2)
                if value and len(value.replace(",", "").replace(".", "")) >= 4:
                    stat = ExtractedStatistic(
                        value=value,
                        type=StatisticType.COUNT,
                        context=self._extract_context(sentence),
                        source_sentence=sentence.strip(),
                        has_source=self._has_citation(sentence),
                        unit=unit
                    )
                    statistics.append(stat)
        
        return statistics
    
    async def detect_errors(
        self,
        content: str,
        statistics: List[ExtractedStatistic]
    ) -> List[StatisticalError]:
        """
        Ä°statistiksel hatalarÄ± tespit et.
        
        Args:
            content: DokÃ¼man iÃ§eriÄŸi
            statistics: Ã‡Ä±karÄ±lan istatistikler
            
        Returns:
            Tespit edilen hatalar
        """
        errors = []
        
        # Kaynak eksikliÄŸi kontrolÃ¼
        for stat in statistics:
            if not stat.has_source and stat.type in [StatisticType.PERCENTAGE, StatisticType.COUNT]:
                errors.append(StatisticalError(
                    error_type="Kaynak EksikliÄŸi",
                    description=f"'{stat.value}' deÄŸeri iÃ§in kaynak belirtilmemiÅŸ",
                    location=stat.source_sentence[:50] + "...",
                    severity="medium",
                    suggestion="Bu istatistik iÃ§in kaynak ekleyin"
                ))
        
        # Ã‡eliÅŸkili istatistikler
        percentages = [s for s in statistics if s.type == StatisticType.PERCENTAGE]
        for i, stat1 in enumerate(percentages):
            for stat2 in percentages[i+1:]:
                if self._check_contradiction(stat1, stat2):
                    errors.append(StatisticalError(
                        error_type="Potansiyel Ã‡eliÅŸki",
                        description=f"'{stat1.value}' ve '{stat2.value}' deÄŸerleri Ã§eliÅŸebilir",
                        location=stat1.source_sentence[:30] + "...",
                        severity="high",
                        suggestion="Bu deÄŸerlerin tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol edin"
                    ))
        
        # LLM ile derin analiz
        if len(statistics) > 0:
            prompt = f"""AÅŸaÄŸÄ±daki istatistiklerde:
1. Matematik hatalarÄ±
2. MantÄ±ksÄ±z deÄŸerler
3. BaÄŸlamla uyumsuzluk
4. GÃ¼ncellik sorunlarÄ±

tespit et.

## Ä°statistikler:
{json.dumps([{"value": s.value, "context": s.context} for s in statistics[:20]], ensure_ascii=False)}

## YanÄ±t (JSON Array):
[{{"error_type": "", "description": "", "severity": "low/medium/high", "suggestion": ""}}]"""

            response = await self._llm_call(prompt)
            
            try:
                json_match = re.search(r'\[[\s\S]*\]', response)
                if json_match:
                    data = json.loads(json_match.group())
                    for item in data:
                        if item.get("description"):
                            errors.append(StatisticalError(
                                error_type=item.get("error_type", "Genel"),
                                description=item.get("description", ""),
                                location="",
                                severity=item.get("severity", "medium"),
                                suggestion=item.get("suggestion", "")
                            ))
            except:
                pass
        
        return errors
    
    async def recommend_visualizations(
        self,
        statistics: List[ExtractedStatistic]
    ) -> List[VisualizationRecommendation]:
        """
        GÃ¶rselleÅŸtirme Ã¶ner.
        
        Args:
            statistics: Ã‡Ä±karÄ±lan istatistikler
            
        Returns:
            GÃ¶rselleÅŸtirme Ã¶nerileri
        """
        recommendations = []
        
        # YÃ¼zdelik daÄŸÄ±lÄ±m varsa
        percentages = [s for s in statistics if s.type == StatisticType.PERCENTAGE]
        if len(percentages) >= 3:
            recommendations.append(VisualizationRecommendation(
                chart_type=VisualizationType.PIE_CHART,
                title="YÃ¼zde DaÄŸÄ±lÄ±mÄ±",
                data_points=[{"label": s.context[:30], "value": s.value} for s in percentages[:5]],
                reason="Birden fazla yÃ¼zdelik deÄŸer pasta grafikte gÃ¶sterilebilir",
                priority=1
            ))
        
        # Zaman serisi varsa
        stats_with_years = [s for s in statistics if s.year]
        if len(stats_with_years) >= 2:
            recommendations.append(VisualizationRecommendation(
                chart_type=VisualizationType.LINE_CHART,
                title="Zaman Serisi Analizi",
                data_points=[{"year": s.year, "value": s.value} for s in stats_with_years],
                reason="YÄ±llara gÃ¶re deÄŸiÅŸim Ã§izgi grafikte gÃ¶sterilebilir",
                priority=2
            ))
        
        # KarÅŸÄ±laÅŸtÄ±rmalÄ± veriler
        counts = [s for s in statistics if s.type == StatisticType.COUNT]
        if len(counts) >= 2:
            recommendations.append(VisualizationRecommendation(
                chart_type=VisualizationType.BAR_CHART,
                title="KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz",
                data_points=[{"label": s.context[:30], "value": s.value} for s in counts[:6]],
                reason="SayÄ±sal karÅŸÄ±laÅŸtÄ±rmalar bar grafikte etkili",
                priority=3
            ))
        
        # Tablo Ã¶nerisi (her zaman)
        if len(statistics) >= 3:
            recommendations.append(VisualizationRecommendation(
                chart_type=VisualizationType.TABLE,
                title="Ä°statistik Ã–zet Tablosu",
                data_points=[{"metric": s.context[:40], "value": s.value} for s in statistics[:10]],
                reason="TÃ¼m istatistikler Ã¶zet tabloda sunulabilir",
                priority=4
            ))
        
        return sorted(recommendations, key=lambda x: x.priority)
    
    async def calculate_summary_statistics(
        self,
        data: List[float],
        label: str = "Veri"
    ) -> Dict[str, Any]:
        """
        Ã–zet istatistikler hesapla.
        
        Args:
            data: SayÄ±sal veri listesi
            label: Veri etiketi
            
        Returns:
            Ã–zet istatistikler
        """
        if not data:
            return {"error": "Veri bulunamadÄ±"}
        
        n = len(data)
        sorted_data = sorted(data)
        
        mean = sum(data) / n
        variance = sum((x - mean) ** 2 for x in data) / n
        std_dev = variance ** 0.5
        
        median = sorted_data[n // 2] if n % 2 else (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
        
        q1 = sorted_data[n // 4]
        q3 = sorted_data[3 * n // 4]
        iqr = q3 - q1
        
        return {
            "label": label,
            "n": n,
            "mean": round(mean, 2),
            "median": median,
            "std_dev": round(std_dev, 2),
            "min": min(data),
            "max": max(data),
            "range": max(data) - min(data),
            "q1": q1,
            "q3": q3,
            "iqr": iqr
        }
    
    def _extract_context(self, sentence: str) -> str:
        """BaÄŸlam Ã§Ä±kar."""
        # Anahtar kelimeleri bul
        keywords = ["oranÄ±", "yÃ¼zdesi", "sayÄ±sÄ±", "artÄ±ÅŸ", "azalÄ±ÅŸ", 
                   "bÃ¼yÃ¼me", "dÃ¼ÅŸÃ¼ÅŸ", "deÄŸer", "miktar", "toplam"]
        
        for keyword in keywords:
            if keyword in sentence.lower():
                # Anahtar kelime etrafÄ±ndaki baÄŸlamÄ± al
                idx = sentence.lower().find(keyword)
                start = max(0, idx - 20)
                end = min(len(sentence), idx + len(keyword) + 20)
                return sentence[start:end].strip()
        
        return sentence[:50].strip()
    
    def _has_citation(self, sentence: str) -> bool:
        """AtÄ±f var mÄ± kontrol et."""
        patterns = [
            r'\([^)]+\d{4}\)',  # APA style
            r'\[\d+\]',         # IEEE style
            r'[A-Z][a-z]+\s+\(\d{4}\)',  # Author (year)
        ]
        return any(re.search(p, sentence) for p in patterns)
    
    def _validate_percentage(self, stat: ExtractedStatistic):
        """YÃ¼zdeyi doÄŸrula."""
        try:
            value = float(stat.value.replace("%", "").replace(",", "."))
            if value < 0:
                stat.is_valid = False
                stat.issues.append("Negatif yÃ¼zde deÄŸeri")
            elif value > 100:
                # %100'den bÃ¼yÃ¼k olabilir (bÃ¼yÃ¼me oranÄ± gibi)
                stat.issues.append("100'den bÃ¼yÃ¼k - bÃ¼yÃ¼me oranÄ± olabilir")
        except:
            pass
    
    def _validate_p_value(self, stat: ExtractedStatistic):
        """p-deÄŸerini doÄŸrula."""
        try:
            value = float(stat.value.split("=")[1].replace(",", "."))
            if value < 0 or value > 1:
                stat.is_valid = False
                stat.issues.append("p-deÄŸeri 0-1 arasÄ±nda olmalÄ±")
        except:
            pass
    
    def _check_contradiction(
        self, 
        stat1: ExtractedStatistic, 
        stat2: ExtractedStatistic
    ) -> bool:
        """Ä°ki istatistik Ã§eliÅŸiyor mu?"""
        # AynÄ± baÄŸlamda farklÄ± deÄŸerler
        if stat1.context and stat2.context:
            context_overlap = set(stat1.context.lower().split()) & set(stat2.context.lower().split())
            if len(context_overlap) >= 3 and stat1.value != stat2.value:
                return True
        return False
    
    def _create_summary(
        self, 
        statistics: List[ExtractedStatistic]
    ) -> Dict[str, Any]:
        """Ã–zet oluÅŸtur."""
        return {
            "total": len(statistics),
            "by_type": {
                t.value: len([s for s in statistics if s.type == t])
                for t in StatisticType
            },
            "with_source": len([s for s in statistics if s.has_source]),
            "without_source": len([s for s in statistics if not s.has_source]),
            "with_issues": len([s for s in statistics if s.issues])
        }
    
    async def _llm_call(self, prompt: str, timeout: int = 300) -> str:
        """LLM Ã§aÄŸrÄ±sÄ± yap."""
        try:
            messages = [{"role": "user", "content": prompt}]
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    llm_manager.chat,
                    messages=messages,
                    model_type="default"
                ),
                timeout=timeout
            )
            return response.get("content", "") if isinstance(response, dict) else str(response)
        except Exception as e:
            return f"Error: {str(e)}"
