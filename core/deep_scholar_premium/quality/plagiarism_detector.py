"""
PlagiarismDetector - Ä°ntihal Tespit ModÃ¼lÃ¼
==========================================

Tespit YÃ¶ntemleri:
1. Metin eÅŸleÅŸtirme (n-gram)
2. Semantik benzerlik (embedding)
3. Kaynak eÅŸleÅŸtirme
4. Parafraz tespiti
5. Self-plagiarism kontrolÃ¼
"""

import asyncio
import hashlib
import re
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
from collections import Counter


class SimilarityLevel(str, Enum):
    """Benzerlik seviyesi."""
    NONE = "none"           # %0-10
    LOW = "low"             # %10-30
    MODERATE = "moderate"   # %30-50
    HIGH = "high"           # %50-70
    VERY_HIGH = "very_high" # %70-90
    EXACT = "exact"         # %90-100


@dataclass
class PlagiarismMatch:
    """Ä°ntihal eÅŸleÅŸmesi."""
    text: str
    source_text: str
    source_id: Optional[str]
    source_title: Optional[str]
    similarity: float  # 0-1
    match_type: str    # "exact", "paraphrase", "semantic"
    start_position: int
    end_position: int


@dataclass
class PlagiarismReport:
    """Ä°ntihal raporu."""
    overall_similarity: float
    level: SimilarityLevel
    total_matches: int
    matches: List[PlagiarismMatch]
    
    # Ä°statistikler
    exact_matches: int = 0
    paraphrase_matches: int = 0
    semantic_matches: int = 0
    
    # Ã–zet
    summary: str = ""
    recommendations: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "overall_similarity": round(self.overall_similarity * 100, 1),
            "level": self.level.value,
            "total_matches": self.total_matches,
            "exact_matches": self.exact_matches,
            "paraphrase_matches": self.paraphrase_matches,
            "semantic_matches": self.semantic_matches,
            "summary": self.summary,
            "recommendations": self.recommendations
        }
    
    def to_markdown(self) -> str:
        lines = [
            "# ğŸ“‹ Ä°ntihal Raporu",
            "",
            f"**Genel Benzerlik:** %{round(self.overall_similarity * 100, 1)}",
            f"**Seviye:** {self.level.value.replace('_', ' ').title()}",
            f"**Toplam EÅŸleÅŸme:** {self.total_matches}",
            "",
            "## EÅŸleÅŸme DaÄŸÄ±lÄ±mÄ±",
            f"- Tam eÅŸleÅŸme: {self.exact_matches}",
            f"- Parafraz: {self.paraphrase_matches}",
            f"- Semantik: {self.semantic_matches}",
            ""
        ]
        
        if self.matches:
            lines.extend(["## Tespit Edilen EÅŸleÅŸmeler", ""])
            for i, match in enumerate(self.matches[:10], 1):
                lines.append(f"### {i}. EÅŸleÅŸme (%{round(match.similarity * 100)})")
                lines.append(f"> {match.text[:200]}...")
                if match.source_title:
                    lines.append(f"*Kaynak: {match.source_title}*")
                lines.append("")
        
        if self.recommendations:
            lines.extend(["## Ã–neriler", ""])
            for rec in self.recommendations:
                lines.append(f"- {rec}")
        
        return "\n".join(lines)


class PlagiarismDetector:
    """
    Ä°ntihal Tespit ModÃ¼lÃ¼
    
    Ã‡oklu yÃ¶ntemle intihal tespiti yapar.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.known_sources: Dict[str, str] = {}  # source_id -> content
        self.ngram_index: Dict[str, List[str]] = {}  # ngram -> [source_ids]
        
        # Parametreler
        self.ngram_size = config.get("ngram_size", 5) if config else 5
        self.min_match_length = config.get("min_match_length", 10) if config else 10
        self.similarity_threshold = config.get("similarity_threshold", 0.3) if config else 0.3
    
    async def check_document(
        self,
        content: str,
        sources: Optional[List[Dict[str, Any]]] = None
    ) -> PlagiarismReport:
        """
        DokÃ¼manÄ± intihal iÃ§in kontrol et.
        
        Args:
            content: Kontrol edilecek iÃ§erik
            sources: KarÅŸÄ±laÅŸtÄ±rÄ±lacak kaynaklar
            
        Returns:
            Ä°ntihal raporu
        """
        matches: List[PlagiarismMatch] = []
        
        # KaynaklarÄ± indexe ekle
        if sources:
            for source in sources:
                source_id = source.get("id", hashlib.md5(
                    source.get("content", "")[:100].encode()
                ).hexdigest()[:8])
                source_content = source.get("content", "") or source.get("abstract", "")
                if source_content:
                    self.add_source(source_id, source_content, source.get("title"))
        
        # N-gram tabanlÄ± tam eÅŸleÅŸme kontrolÃ¼
        exact_matches = await self._check_exact_matches(content)
        matches.extend(exact_matches)
        
        # Parafraz tespiti
        paraphrase_matches = await self._check_paraphrases(content)
        matches.extend(paraphrase_matches)
        
        # Semantik benzerlik (opsiyonel, embedding gerektirir)
        semantic_matches = await self._check_semantic_similarity(content)
        matches.extend(semantic_matches)
        
        # DuplikasyonlarÄ± kaldÄ±r
        matches = self._deduplicate_matches(matches)
        
        # Genel benzerlik hesapla
        overall_similarity = self._calculate_overall_similarity(content, matches)
        
        # Rapor oluÅŸtur
        return self._create_report(overall_similarity, matches)
    
    async def check_section(
        self,
        section_content: str,
        section_title: str
    ) -> PlagiarismReport:
        """Tek bir bÃ¶lÃ¼mÃ¼ kontrol et."""
        return await self.check_document(section_content)
    
    def add_source(
        self,
        source_id: str,
        content: str,
        title: Optional[str] = None
    ):
        """
        KarÅŸÄ±laÅŸtÄ±rma iÃ§in kaynak ekle.
        
        Args:
            source_id: Kaynak kimliÄŸi
            content: Kaynak iÃ§eriÄŸi
            title: Kaynak baÅŸlÄ±ÄŸÄ±
        """
        self.known_sources[source_id] = {
            "content": content,
            "title": title
        }
        
        # N-gram indexini gÃ¼ncelle
        ngrams = self._get_ngrams(content)
        for ngram in ngrams:
            ngram_hash = hashlib.md5(ngram.encode()).hexdigest()
            if ngram_hash not in self.ngram_index:
                self.ngram_index[ngram_hash] = []
            if source_id not in self.ngram_index[ngram_hash]:
                self.ngram_index[ngram_hash].append(source_id)
    
    async def _check_exact_matches(
        self,
        content: str
    ) -> List[PlagiarismMatch]:
        """Tam eÅŸleÅŸme kontrolÃ¼ (n-gram tabanlÄ±)."""
        matches = []
        
        # Ä°Ã§eriÄŸi cÃ¼mlelere bÃ¶l
        sentences = re.split(r'[.!?]+', content)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence.split()) < self.min_match_length:
                continue
            
            # N-gramlarÄ± kontrol et
            ngrams = self._get_ngrams(sentence)
            
            for ngram in ngrams:
                ngram_hash = hashlib.md5(ngram.encode()).hexdigest()
                
                if ngram_hash in self.ngram_index:
                    for source_id in self.ngram_index[ngram_hash]:
                        source_info = self.known_sources.get(source_id, {})
                        source_content = source_info.get("content", "")
                        
                        # Daha uzun eÅŸleÅŸme bul
                        match_start, match_end = self._find_longest_match(
                            sentence, source_content
                        )
                        
                        if match_end - match_start >= self.min_match_length * 5:
                            matched_text = sentence[match_start:match_end]
                            
                            matches.append(PlagiarismMatch(
                                text=matched_text,
                                source_text=matched_text,
                                source_id=source_id,
                                source_title=source_info.get("title"),
                                similarity=1.0,
                                match_type="exact",
                                start_position=content.find(sentence),
                                end_position=content.find(sentence) + len(sentence)
                            ))
        
        return matches
    
    async def _check_paraphrases(
        self,
        content: str
    ) -> List[PlagiarismMatch]:
        """Parafraz tespiti."""
        matches = []
        
        # Her kaynak iÃ§in benzerlik kontrolÃ¼
        sentences = re.split(r'[.!?]+', content)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence.split()) < 5:
                continue
            
            for source_id, source_info in self.known_sources.items():
                source_content = source_info.get("content", "")
                source_sentences = re.split(r'[.!?]+', source_content)
                
                for source_sentence in source_sentences:
                    source_sentence = source_sentence.strip()
                    if len(source_sentence.split()) < 5:
                        continue
                    
                    # Jaccard benzerliÄŸi
                    similarity = self._jaccard_similarity(sentence, source_sentence)
                    
                    if 0.5 <= similarity < 0.9:  # Parafraz aralÄ±ÄŸÄ±
                        matches.append(PlagiarismMatch(
                            text=sentence,
                            source_text=source_sentence,
                            source_id=source_id,
                            source_title=source_info.get("title"),
                            similarity=similarity,
                            match_type="paraphrase",
                            start_position=content.find(sentence),
                            end_position=content.find(sentence) + len(sentence)
                        ))
                        break
        
        return matches
    
    async def _check_semantic_similarity(
        self,
        content: str
    ) -> List[PlagiarismMatch]:
        """Semantik benzerlik kontrolÃ¼ (basitleÅŸtirilmiÅŸ)."""
        # Bu Ã¶zellik iÃ§in embedding modeli gerekir
        # Åimdilik boÅŸ dÃ¶ndÃ¼r
        return []
    
    def _get_ngrams(self, text: str) -> List[str]:
        """N-gramlarÄ± Ã§Ä±kar."""
        words = text.lower().split()
        ngrams = []
        
        for i in range(len(words) - self.ngram_size + 1):
            ngram = " ".join(words[i:i + self.ngram_size])
            ngrams.append(ngram)
        
        return ngrams
    
    def _find_longest_match(
        self,
        text1: str,
        text2: str
    ) -> Tuple[int, int]:
        """En uzun eÅŸleÅŸen alt diziyi bul."""
        words1 = text1.lower().split()
        words2 = text2.lower().split()
        
        # Basit LCS (Longest Common Subsequence) yaklaÅŸÄ±mÄ±
        max_length = 0
        max_start = 0
        
        for i in range(len(words1)):
            for j in range(len(words2)):
                length = 0
                while (i + length < len(words1) and 
                       j + length < len(words2) and
                       words1[i + length] == words2[j + length]):
                    length += 1
                
                if length > max_length:
                    max_length = length
                    max_start = sum(len(w) + 1 for w in words1[:i])
        
        return max_start, max_start + max_length * 6  # YaklaÅŸÄ±k karakter pozisyonu
    
    def _jaccard_similarity(self, text1: str, text2: str) -> float:
        """Jaccard benzerliÄŸi hesapla."""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        
        return intersection / union if union > 0 else 0.0
    
    def _deduplicate_matches(
        self,
        matches: List[PlagiarismMatch]
    ) -> List[PlagiarismMatch]:
        """Ã‡akÄ±ÅŸan eÅŸleÅŸmeleri birleÅŸtir."""
        if not matches:
            return []
        
        # Pozisyona gÃ¶re sÄ±rala
        sorted_matches = sorted(matches, key=lambda m: m.start_position)
        
        result = [sorted_matches[0]]
        
        for match in sorted_matches[1:]:
            last = result[-1]
            
            # Ã‡akÄ±ÅŸma kontrolÃ¼
            if match.start_position < last.end_position:
                # En yÃ¼ksek benzerliÄŸi tut
                if match.similarity > last.similarity:
                    result[-1] = match
            else:
                result.append(match)
        
        return result
    
    def _calculate_overall_similarity(
        self,
        content: str,
        matches: List[PlagiarismMatch]
    ) -> float:
        """Genel benzerlik oranÄ±nÄ± hesapla."""
        if not matches:
            return 0.0
        
        total_length = len(content)
        if total_length == 0:
            return 0.0
        
        matched_chars = sum(m.end_position - m.start_position for m in matches)
        
        return min(matched_chars / total_length, 1.0)
    
    def _create_report(
        self,
        overall_similarity: float,
        matches: List[PlagiarismMatch]
    ) -> PlagiarismReport:
        """Rapor oluÅŸtur."""
        # Seviye belirle
        if overall_similarity < 0.1:
            level = SimilarityLevel.NONE
        elif overall_similarity < 0.3:
            level = SimilarityLevel.LOW
        elif overall_similarity < 0.5:
            level = SimilarityLevel.MODERATE
        elif overall_similarity < 0.7:
            level = SimilarityLevel.HIGH
        elif overall_similarity < 0.9:
            level = SimilarityLevel.VERY_HIGH
        else:
            level = SimilarityLevel.EXACT
        
        # EÅŸleÅŸme tÃ¼rlerini say
        exact_count = sum(1 for m in matches if m.match_type == "exact")
        paraphrase_count = sum(1 for m in matches if m.match_type == "paraphrase")
        semantic_count = sum(1 for m in matches if m.match_type == "semantic")
        
        # Ã–zet
        if level in [SimilarityLevel.NONE, SimilarityLevel.LOW]:
            summary = "Ä°ntihal riski dÃ¼ÅŸÃ¼k. Ä°Ã§erik bÃ¼yÃ¼k Ã¶lÃ§Ã¼de orijinal gÃ¶rÃ¼nÃ¼yor."
        elif level == SimilarityLevel.MODERATE:
            summary = "Orta dÃ¼zeyde benzerlik tespit edildi. BazÄ± bÃ¶lÃ¼mlerin yeniden yazÄ±lmasÄ± Ã¶nerilir."
        else:
            summary = "YÃ¼ksek benzerlik tespit edildi. Ciddi revizyon gerekli."
        
        # Ã–neriler
        recommendations = []
        if exact_count > 0:
            recommendations.append("Tam eÅŸleÅŸen bÃ¶lÃ¼mleri kendi kelimelerinizle yeniden yazÄ±n")
        if paraphrase_count > 0:
            recommendations.append("Parafraz bÃ¶lÃ¼mlerini farklÄ± bir perspektiften ele alÄ±n")
        if level in [SimilarityLevel.HIGH, SimilarityLevel.VERY_HIGH]:
            recommendations.append("TÃ¼m alÄ±ntÄ±larÄ± uygun ÅŸekilde kaynak gÃ¶stererek iÅŸaretleyin")
        
        return PlagiarismReport(
            overall_similarity=overall_similarity,
            level=level,
            total_matches=len(matches),
            matches=matches,
            exact_matches=exact_count,
            paraphrase_matches=paraphrase_count,
            semantic_matches=semantic_count,
            summary=summary,
            recommendations=recommendations
        )
    
    def clear_sources(self):
        """Kaynak indexini temizle."""
        self.known_sources.clear()
        self.ngram_index.clear()
