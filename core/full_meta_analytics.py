"""
Full Meta Learning - Analytics Module
Geli≈ümi≈ü √∂ƒürenme analitiƒüi ve raporlama

Features:
- Learning Velocity Graph: √ñƒürenme hƒ±zƒ± grafiƒüi
- Strength Map: Konu bazlƒ± g√º√ß haritasƒ±
- Time Investment ROI: Zaman yatƒ±rƒ±mƒ± getirisi
- Optimal Study Plan: Optimal √ßalƒ±≈üma planƒ±
- Burnout Detector: T√ºkenmi≈ülik algƒ±lama
- Predicted Exam Score: Tahmini sƒ±nav puanƒ±
"""

import uuid
import math
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from dataclasses import dataclass, field
from collections import defaultdict
import statistics


# ============ ENUMS ============

class MetricType(str, Enum):
    """Metrik t√ºrleri"""
    VELOCITY = "velocity"            # √ñƒürenme hƒ±zƒ±
    RETENTION = "retention"          # Hatƒ±rlama oranƒ±
    ACCURACY = "accuracy"            # Doƒüruluk
    CONSISTENCY = "consistency"      # Tutarlƒ±lƒ±k
    EFFICIENCY = "efficiency"        # Verimlilik
    ENGAGEMENT = "engagement"        # Katƒ±lƒ±m


class StrengthLevel(str, Enum):
    """G√º√ß seviyeleri"""
    WEAK = "weak"                    # 0-40
    DEVELOPING = "developing"        # 40-60
    MODERATE = "moderate"            # 60-75
    STRONG = "strong"                # 75-90
    MASTERED = "mastered"            # 90-100


class BurnoutRisk(str, Enum):
    """T√ºkenmi≈ülik risk seviyeleri"""
    LOW = "low"                      # D√º≈ü√ºk risk
    MODERATE = "moderate"            # Orta risk
    HIGH = "high"                    # Y√ºksek risk
    CRITICAL = "critical"            # Kritik risk


class StudySessionType(str, Enum):
    """√áalƒ±≈üma oturumu t√ºrleri"""
    LEARNING = "learning"            # Yeni √∂ƒürenme
    REVIEW = "review"                # Tekrar
    PRACTICE = "practice"            # Pratik
    ASSESSMENT = "assessment"        # Deƒüerlendirme
    MIXED = "mixed"                  # Karƒ±≈üƒ±k


class TrendDirection(str, Enum):
    """Trend y√∂n√º"""
    IMPROVING = "improving"          # ƒ∞yile≈üme
    STABLE = "stable"                # Stabil
    DECLINING = "declining"          # D√º≈ü√º≈ü


# ============ DATA CLASSES ============

@dataclass
class LearningDataPoint:
    """√ñƒürenme veri noktasƒ±"""
    timestamp: datetime = field(default_factory=datetime.now)
    
    # Metrikler
    items_learned: int = 0
    items_reviewed: int = 0
    correct_count: int = 0
    incorrect_count: int = 0
    
    # Zaman
    duration_minutes: int = 0
    active_time_minutes: int = 0     # Ger√ßek aktif s√ºre
    
    # Kalite
    retention_rate: float = 0.0
    accuracy_rate: float = 0.0
    
    # Baƒülam
    session_type: StudySessionType = StudySessionType.MIXED
    topics: List[str] = field(default_factory=list)


@dataclass
class LearningVelocity:
    """√ñƒürenme hƒ±zƒ±"""
    user_id: str = ""
    
    # Hƒ±z metrikleri
    items_per_hour: float = 0.0
    concepts_per_day: float = 0.0
    retention_per_review: float = 0.0
    
    # Trend
    velocity_trend: TrendDirection = TrendDirection.STABLE
    velocity_change_percent: float = 0.0
    
    # Kar≈üƒ±la≈ütƒ±rma
    percentile_rank: int = 50        # Diƒüer kullanƒ±cƒ±lara g√∂re
    
    # Zaman serisi
    daily_velocities: List[float] = field(default_factory=list)
    weekly_average: float = 0.0
    monthly_average: float = 0.0


@dataclass
class TopicStrength:
    """Konu g√ºc√º"""
    topic: str = ""
    
    # G√º√ß metrikleri
    strength_score: float = 0.0      # 0-100
    level: StrengthLevel = StrengthLevel.DEVELOPING
    
    # Detay
    total_items: int = 0
    mastered_items: int = 0
    struggling_items: int = 0
    
    # Trend
    trend: TrendDirection = TrendDirection.STABLE
    last_studied: Optional[datetime] = None
    
    # Alt konular
    subtopics: Dict[str, float] = field(default_factory=dict)


@dataclass
class TimeInvestmentROI:
    """Zaman yatƒ±rƒ±mƒ± ROI"""
    period: str = ""                 # "day", "week", "month"
    
    # Yatƒ±rƒ±m
    total_time_minutes: int = 0
    active_learning_minutes: int = 0
    review_minutes: int = 0
    
    # Getiri
    new_concepts_learned: int = 0
    retention_gained: float = 0.0    # Toplam retention artƒ±≈üƒ±
    mastery_gained: float = 0.0      # Mastery artƒ±≈üƒ±
    
    # ROI hesaplama
    learning_efficiency: float = 0.0  # concepts per hour
    retention_per_minute: float = 0.0
    
    # Kar≈üƒ±la≈ütƒ±rma
    roi_score: float = 0.0           # 0-100
    optimal_allocation: Dict[str, float] = field(default_factory=dict)


@dataclass
class StudyPlanSlot:
    """√áalƒ±≈üma planƒ± slotu"""
    date: datetime = field(default_factory=datetime.now)
    time_slot: str = ""              # "09:00-10:00"
    
    # ƒ∞√ßerik
    topics: List[str] = field(default_factory=list)
    session_type: StudySessionType = StudySessionType.LEARNING
    
    # Hedefler
    target_items: int = 0
    target_duration_minutes: int = 25
    
    # √ñncelik
    priority: str = "medium"         # low, medium, high, critical
    
    # Durum
    completed: bool = False
    actual_duration: int = 0


@dataclass
class OptimalStudyPlan:
    """Optimal √ßalƒ±≈üma planƒ±"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    user_id: str = ""
    
    # Plan detaylarƒ±
    start_date: datetime = field(default_factory=datetime.now)
    end_date: datetime = field(default_factory=datetime.now)
    
    slots: List[StudyPlanSlot] = field(default_factory=list)
    
    # Hedefler
    target_topics: List[str] = field(default_factory=list)
    target_mastery: float = 80.0
    
    # √ñneriler
    daily_goal_minutes: int = 60
    optimal_times: List[str] = field(default_factory=list)
    break_frequency: int = 25         # Pomodoro
    
    # Meta
    generated_at: datetime = field(default_factory=datetime.now)


@dataclass
class BurnoutIndicator:
    """T√ºkenmi≈ülik g√∂stergesi"""
    user_id: str = ""
    assessed_at: datetime = field(default_factory=datetime.now)
    
    # Risk fakt√∂rleri (0-100)
    overwork_score: float = 0.0      # A≈üƒ±rƒ± √ßalƒ±≈üma
    fatigue_score: float = 0.0       # Yorgunluk
    declining_performance: float = 0.0
    irregular_schedule: float = 0.0
    
    # Genel risk
    overall_risk: BurnoutRisk = BurnoutRisk.LOW
    risk_score: float = 0.0          # 0-100
    
    # Uyarƒ±lar
    warnings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)


@dataclass
class ExamScorePrediction:
    """Sƒ±nav puanƒ± tahmini"""
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    
    # Giri≈ü
    topics: List[str] = field(default_factory=list)
    exam_type: str = "general"       # general, midterm, final, certification
    
    # Tahmin
    predicted_score: float = 0.0     # 0-100
    confidence_interval: Tuple[float, float] = (0.0, 0.0)
    confidence_level: float = 0.0    # 0-1
    
    # Detay
    topic_predictions: Dict[str, float] = field(default_factory=dict)
    strong_topics: List[str] = field(default_factory=list)
    weak_topics: List[str] = field(default_factory=list)
    
    # √ñneriler
    study_priorities: List[str] = field(default_factory=list)
    estimated_improvement: Dict[str, float] = field(default_factory=dict)
    
    predicted_at: datetime = field(default_factory=datetime.now)


# ============ ENGINES ============

class LearningVelocityEngine:
    """√ñƒürenme hƒ±zƒ± analiz engine'i"""
    
    def __init__(self):
        self.data_points: Dict[str, List[LearningDataPoint]] = {}
        self.velocities: Dict[str, LearningVelocity] = {}
    
    def record_session(self, user_id: str, 
                      data: Dict[str, Any]) -> LearningDataPoint:
        """Oturum kaydet"""
        point = LearningDataPoint(
            items_learned=data.get("items_learned", 0),
            items_reviewed=data.get("items_reviewed", 0),
            correct_count=data.get("correct", 0),
            incorrect_count=data.get("incorrect", 0),
            duration_minutes=data.get("duration", 0),
            active_time_minutes=data.get("active_time", data.get("duration", 0)),
            session_type=StudySessionType(data.get("type", "mixed")),
            topics=data.get("topics", [])
        )
        
        # Oranlarƒ± hesapla
        total = point.correct_count + point.incorrect_count
        if total > 0:
            point.accuracy_rate = point.correct_count / total
        
        if user_id not in self.data_points:
            self.data_points[user_id] = []
        self.data_points[user_id].append(point)
        
        # Velocity g√ºncelle
        self._update_velocity(user_id)
        
        return point
    
    def _update_velocity(self, user_id: str) -> None:
        """Velocity g√ºncelle"""
        points = self.data_points.get(user_id, [])
        if not points:
            return
        
        # Son 7 g√ºn
        week_ago = datetime.now() - timedelta(days=7)
        recent_points = [p for p in points if p.timestamp > week_ago]
        
        if not recent_points:
            return
        
        # Toplam metrikler
        total_items = sum(p.items_learned + p.items_reviewed for p in recent_points)
        total_hours = sum(p.duration_minutes for p in recent_points) / 60
        
        velocity = LearningVelocity(user_id=user_id)
        
        if total_hours > 0:
            velocity.items_per_hour = total_items / total_hours
        
        # G√ºnl√ºk velocity
        daily_counts = defaultdict(int)
        for p in recent_points:
            date_key = p.timestamp.strftime("%Y-%m-%d")
            daily_counts[date_key] += p.items_learned
        
        velocity.daily_velocities = list(daily_counts.values())
        
        if velocity.daily_velocities:
            velocity.weekly_average = statistics.mean(velocity.daily_velocities)
        
        # Trend hesapla
        if len(velocity.daily_velocities) >= 3:
            first_half = velocity.daily_velocities[:len(velocity.daily_velocities)//2]
            second_half = velocity.daily_velocities[len(velocity.daily_velocities)//2:]
            
            first_avg = statistics.mean(first_half) if first_half else 0
            second_avg = statistics.mean(second_half) if second_half else 0
            
            if first_avg > 0:
                change = (second_avg - first_avg) / first_avg * 100
                velocity.velocity_change_percent = change
                
                if change > 10:
                    velocity.velocity_trend = TrendDirection.IMPROVING
                elif change < -10:
                    velocity.velocity_trend = TrendDirection.DECLINING
                else:
                    velocity.velocity_trend = TrendDirection.STABLE
        
        self.velocities[user_id] = velocity
    
    def get_velocity_graph_data(self, user_id: str, 
                                days: int = 30) -> Dict[str, Any]:
        """Velocity grafik verisi"""
        points = self.data_points.get(user_id, [])
        cutoff = datetime.now() - timedelta(days=days)
        
        recent_points = [p for p in points if p.timestamp > cutoff]
        
        # G√ºnl√ºk grupla
        daily_data = defaultdict(lambda: {"items": 0, "minutes": 0, "correct": 0, "total": 0})
        
        for p in recent_points:
            date_key = p.timestamp.strftime("%Y-%m-%d")
            daily_data[date_key]["items"] += p.items_learned + p.items_reviewed
            daily_data[date_key]["minutes"] += p.duration_minutes
            daily_data[date_key]["correct"] += p.correct_count
            daily_data[date_key]["total"] += p.correct_count + p.incorrect_count
        
        graph_data = []
        for date_str in sorted(daily_data.keys()):
            data = daily_data[date_str]
            hours = data["minutes"] / 60 if data["minutes"] > 0 else 1
            accuracy = data["correct"] / data["total"] if data["total"] > 0 else 0
            
            graph_data.append({
                "date": date_str,
                "items": data["items"],
                "velocity": data["items"] / hours,
                "minutes": data["minutes"],
                "accuracy": accuracy * 100
            })
        
        velocity = self.velocities.get(user_id)
        
        return {
            "data": graph_data,
            "summary": {
                "trend": velocity.velocity_trend.value if velocity else "stable",
                "change": velocity.velocity_change_percent if velocity else 0,
                "weekly_avg": velocity.weekly_average if velocity else 0
            }
        }


class StrengthMapEngine:
    """Konu g√º√ß haritasƒ± engine'i"""
    
    def __init__(self):
        self.strengths: Dict[str, Dict[str, TopicStrength]] = {}
    
    def update_strength(self, user_id: str, topic: str,
                       performance: float,
                       items_count: int = 1) -> TopicStrength:
        """G√º√ß g√ºncelle"""
        if user_id not in self.strengths:
            self.strengths[user_id] = {}
        
        if topic not in self.strengths[user_id]:
            self.strengths[user_id][topic] = TopicStrength(topic=topic)
        
        strength = self.strengths[user_id][topic]
        
        # Exponential moving average ile g√ºncelle
        alpha = 0.3  # Smoothing factor
        strength.strength_score = (1 - alpha) * strength.strength_score + alpha * (performance * 100)
        strength.total_items += items_count
        
        if performance >= 0.9:
            strength.mastered_items += items_count
        elif performance < 0.5:
            strength.struggling_items += items_count
        
        # Level belirle
        score = strength.strength_score
        if score >= 90:
            strength.level = StrengthLevel.MASTERED
        elif score >= 75:
            strength.level = StrengthLevel.STRONG
        elif score >= 60:
            strength.level = StrengthLevel.MODERATE
        elif score >= 40:
            strength.level = StrengthLevel.DEVELOPING
        else:
            strength.level = StrengthLevel.WEAK
        
        strength.last_studied = datetime.now()
        
        return strength
    
    def get_strength_map(self, user_id: str) -> Dict[str, Any]:
        """G√º√ß haritasƒ± al"""
        user_strengths = self.strengths.get(user_id, {})
        
        if not user_strengths:
            return {"has_data": False, "topics": []}
        
        topics = []
        for topic, strength in user_strengths.items():
            topics.append({
                "topic": topic,
                "score": strength.strength_score,
                "level": strength.level.value,
                "total_items": strength.total_items,
                "mastered": strength.mastered_items,
                "struggling": strength.struggling_items,
                "last_studied": strength.last_studied.isoformat() if strength.last_studied else None,
                "color": self._get_color_for_level(strength.level)
            })
        
        # Skora g√∂re sƒ±rala
        topics.sort(key=lambda x: x["score"], reverse=True)
        
        # √ñzet istatistikler
        scores = [t["score"] for t in topics]
        
        return {
            "has_data": True,
            "topics": topics,
            "summary": {
                "total_topics": len(topics),
                "average_score": statistics.mean(scores) if scores else 0,
                "strongest": topics[0]["topic"] if topics else None,
                "weakest": topics[-1]["topic"] if topics else None,
                "level_distribution": self._get_level_distribution(user_strengths)
            }
        }
    
    def _get_color_for_level(self, level: StrengthLevel) -> str:
        """Seviyeye g√∂re renk"""
        colors = {
            StrengthLevel.WEAK: "#F44336",
            StrengthLevel.DEVELOPING: "#FF9800",
            StrengthLevel.MODERATE: "#FFC107",
            StrengthLevel.STRONG: "#8BC34A",
            StrengthLevel.MASTERED: "#4CAF50"
        }
        return colors.get(level, "#9E9E9E")
    
    def _get_level_distribution(self, 
                               strengths: Dict[str, TopicStrength]) -> Dict[str, int]:
        """Seviye daƒüƒ±lƒ±mƒ±"""
        distribution = defaultdict(int)
        for strength in strengths.values():
            distribution[strength.level.value] += 1
        return dict(distribution)


class TimeROIEngine:
    """Zaman yatƒ±rƒ±mƒ± ROI engine'i"""
    
    def __init__(self):
        self.roi_records: Dict[str, List[TimeInvestmentROI]] = {}
    
    def calculate_roi(self, user_id: str,
                     learning_data: List[LearningDataPoint],
                     period: str = "week") -> TimeInvestmentROI:
        """ROI hesapla"""
        # D√∂nem filtresi
        if period == "day":
            cutoff = datetime.now() - timedelta(days=1)
        elif period == "week":
            cutoff = datetime.now() - timedelta(weeks=1)
        else:
            cutoff = datetime.now() - timedelta(days=30)
        
        filtered_data = [d for d in learning_data if d.timestamp > cutoff]
        
        if not filtered_data:
            return TimeInvestmentROI(period=period)
        
        roi = TimeInvestmentROI(period=period)
        
        # Zaman metrikleri
        roi.total_time_minutes = sum(d.duration_minutes for d in filtered_data)
        roi.active_learning_minutes = sum(
            d.active_time_minutes for d in filtered_data 
            if d.session_type == StudySessionType.LEARNING
        )
        roi.review_minutes = sum(
            d.active_time_minutes for d in filtered_data 
            if d.session_type == StudySessionType.REVIEW
        )
        
        # Getiri metrikleri
        roi.new_concepts_learned = sum(d.items_learned for d in filtered_data)
        roi.retention_gained = sum(d.retention_rate for d in filtered_data) / len(filtered_data)
        
        # Verimlilik
        total_hours = roi.total_time_minutes / 60
        if total_hours > 0:
            roi.learning_efficiency = roi.new_concepts_learned / total_hours
        
        if roi.total_time_minutes > 0:
            roi.retention_per_minute = roi.retention_gained / roi.total_time_minutes
        
        # ROI skoru (0-100)
        # Basit form√ºl: efficiency * retention_quality
        roi.roi_score = min(100, roi.learning_efficiency * roi.retention_gained * 10)
        
        # Optimal daƒüƒ±lƒ±m √∂nerisi
        roi.optimal_allocation = {
            "learning": 0.4,    # %40 yeni √∂ƒürenme
            "review": 0.35,     # %35 tekrar
            "practice": 0.25    # %25 pratik
        }
        
        # Kaydet
        if user_id not in self.roi_records:
            self.roi_records[user_id] = []
        self.roi_records[user_id].append(roi)
        
        return roi
    
    def get_roi_analysis(self, user_id: str) -> Dict[str, Any]:
        """ROI analizi"""
        records = self.roi_records.get(user_id, [])
        
        if not records:
            return {"has_data": False}
        
        latest = records[-1]
        
        # Trend (son 4 kayƒ±t)
        recent = records[-4:] if len(records) >= 4 else records
        roi_trend = [r.roi_score for r in recent]
        
        trend_direction = TrendDirection.STABLE
        if len(roi_trend) >= 2:
            if roi_trend[-1] > roi_trend[0] * 1.1:
                trend_direction = TrendDirection.IMPROVING
            elif roi_trend[-1] < roi_trend[0] * 0.9:
                trend_direction = TrendDirection.DECLINING
        
        return {
            "has_data": True,
            "current_roi": {
                "score": latest.roi_score,
                "efficiency": latest.learning_efficiency,
                "time_invested": latest.total_time_minutes,
                "concepts_learned": latest.new_concepts_learned
            },
            "trend": trend_direction.value,
            "optimal_allocation": latest.optimal_allocation,
            "recommendations": self._get_roi_recommendations(latest)
        }
    
    def _get_roi_recommendations(self, roi: TimeInvestmentROI) -> List[str]:
        """ROI √∂nerileri"""
        recommendations = []
        
        if roi.roi_score < 50:
            recommendations.append("√ñƒürenme verimliliƒüini artƒ±rmak i√ßin odaklanma s√ºrelerini kƒ±salt")
        
        if roi.review_minutes < roi.active_learning_minutes * 0.5:
            recommendations.append("Daha fazla tekrar yap - retention artƒ±rmak i√ßin")
        
        if roi.learning_efficiency < 5:
            recommendations.append("√ñƒürenme hƒ±zƒ±n d√º≈ü√ºk, aktif √∂ƒürenme tekniklerini dene")
        
        if not recommendations:
            recommendations.append("Harika gidiyorsun! Bu tempoyu koru.")
        
        return recommendations


class StudyPlanEngine:
    """Optimal √ßalƒ±≈üma planƒ± engine'i"""
    
    def __init__(self):
        self.plans: Dict[str, OptimalStudyPlan] = {}
    
    def generate_plan(self, user_id: str,
                     topics: List[str],
                     available_hours: Dict[str, List[str]],  # {"Monday": ["09:00", "14:00"], ...}
                     target_mastery: float = 80.0,
                     duration_days: int = 7) -> OptimalStudyPlan:
        """Plan olu≈ütur"""
        plan = OptimalStudyPlan(
            user_id=user_id,
            end_date=datetime.now() + timedelta(days=duration_days),
            target_topics=topics,
            target_mastery=target_mastery
        )
        
        slots = []
        current_date = datetime.now()
        
        weekdays = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
        
        for day_offset in range(duration_days):
            plan_date = current_date + timedelta(days=day_offset)
            weekday = weekdays[plan_date.weekday()]
            
            day_hours = available_hours.get(weekday, [])
            
            for hour in day_hours:
                # Her slot i√ßin topic se√ß (round-robin)
                topic_idx = len(slots) % len(topics)
                topic = topics[topic_idx]
                
                # Session type belirle
                if len(slots) % 3 == 0:
                    session_type = StudySessionType.LEARNING
                elif len(slots) % 3 == 1:
                    session_type = StudySessionType.REVIEW
                else:
                    session_type = StudySessionType.PRACTICE
                
                slot = StudyPlanSlot(
                    date=plan_date.replace(hour=int(hour.split(":")[0]), minute=0),
                    time_slot=f"{hour}-{int(hour.split(':')[0])+1}:00",
                    topics=[topic],
                    session_type=session_type,
                    target_items=10,
                    target_duration_minutes=25,
                    priority="medium"
                )
                slots.append(slot)
        
        plan.slots = slots
        plan.daily_goal_minutes = 60
        plan.optimal_times = ["09:00", "14:00", "19:00"]
        
        self.plans[plan.id] = plan
        return plan
    
    def get_today_plan(self, user_id: str) -> Dict[str, Any]:
        """Bug√ºnk√º planƒ± al"""
        user_plans = [p for p in self.plans.values() if p.user_id == user_id]
        if not user_plans:
            return {"has_plan": False}
        
        latest_plan = user_plans[-1]
        today = datetime.now().date()
        
        today_slots = [s for s in latest_plan.slots if s.date.date() == today]
        
        completed = sum(1 for s in today_slots if s.completed)
        
        return {
            "has_plan": True,
            "slots": [
                {
                    "time": s.time_slot,
                    "topics": s.topics,
                    "type": s.session_type.value,
                    "duration": s.target_duration_minutes,
                    "completed": s.completed,
                    "priority": s.priority
                }
                for s in today_slots
            ],
            "progress": completed / len(today_slots) * 100 if today_slots else 0,
            "remaining_slots": len(today_slots) - completed
        }


class BurnoutDetectorEngine:
    """T√ºkenmi≈ülik algƒ±lama engine'i"""
    
    # Risk fakt√∂rleri e≈üikleri
    THRESHOLDS = {
        "daily_hours_warning": 4,        # 4+ saat/g√ºn uyarƒ±
        "daily_hours_critical": 6,       # 6+ saat/g√ºn kritik
        "consecutive_days_warning": 7,   # 7 g√ºn √ºst √ºste
        "performance_drop_warning": 15,  # %15 performans d√º≈ü√º≈ü√º
        "irregular_schedule_threshold": 0.5  # %50'den az d√ºzenli
    }
    
    def __init__(self):
        self.indicators: Dict[str, List[BurnoutIndicator]] = {}
    
    def assess_burnout_risk(self, user_id: str,
                           recent_sessions: List[LearningDataPoint]) -> BurnoutIndicator:
        """T√ºkenmi≈ülik riski deƒüerlendir"""
        indicator = BurnoutIndicator(user_id=user_id)
        
        if not recent_sessions:
            indicator.overall_risk = BurnoutRisk.LOW
            return indicator
        
        # Son 14 g√ºn√º analiz et
        two_weeks_ago = datetime.now() - timedelta(days=14)
        recent = [s for s in recent_sessions if s.timestamp > two_weeks_ago]
        
        # 1. A≈üƒ±rƒ± √ßalƒ±≈üma skoru
        daily_minutes = defaultdict(int)
        for s in recent:
            date_key = s.timestamp.strftime("%Y-%m-%d")
            daily_minutes[date_key] += s.duration_minutes
        
        high_workload_days = sum(1 for m in daily_minutes.values() 
                                if m > self.THRESHOLDS["daily_hours_warning"] * 60)
        indicator.overwork_score = min(100, high_workload_days * 15)
        
        if any(m > self.THRESHOLDS["daily_hours_critical"] * 60 for m in daily_minutes.values()):
            indicator.warnings.append("‚ö†Ô∏è Bazƒ± g√ºnlerde 6+ saat √ßalƒ±≈üma tespit edildi")
        
        # 2. Yorgunluk skoru (artan session s√ºreleri = d√º≈üen verimlilik)
        if len(recent) >= 5:
            durations = [s.duration_minutes for s in recent[-5:]]
            avg_duration = statistics.mean(durations)
            if avg_duration > 60:  # 1 saatten uzun sessionlar
                indicator.fatigue_score = min(100, (avg_duration - 30) * 2)
        
        # 3. Performans d√º≈ü√º≈ü√º
        if len(recent) >= 10:
            early_accuracy = statistics.mean(s.accuracy_rate for s in recent[:5])
            late_accuracy = statistics.mean(s.accuracy_rate for s in recent[-5:])
            
            if early_accuracy > 0:
                drop = (early_accuracy - late_accuracy) / early_accuracy * 100
                if drop > 0:
                    indicator.declining_performance = min(100, drop * 5)
                    if drop > self.THRESHOLDS["performance_drop_warning"]:
                        indicator.warnings.append(f"üìâ Performansta %{drop:.0f} d√º≈ü√º≈ü")
        
        # 4. D√ºzensiz program
        study_hours = [s.timestamp.hour for s in recent]
        if study_hours:
            hour_variance = statistics.variance(study_hours) if len(study_hours) > 1 else 0
            indicator.irregular_schedule = min(100, hour_variance * 2)
        
        # Genel risk hesapla
        risk_score = (
            indicator.overwork_score * 0.35 +
            indicator.fatigue_score * 0.25 +
            indicator.declining_performance * 0.25 +
            indicator.irregular_schedule * 0.15
        )
        indicator.risk_score = risk_score
        
        # Risk seviyesi belirle
        if risk_score >= 70:
            indicator.overall_risk = BurnoutRisk.CRITICAL
            indicator.recommendations.append("üõë Acil mola ver! En az 2-3 g√ºn dinlen.")
        elif risk_score >= 50:
            indicator.overall_risk = BurnoutRisk.HIGH
            indicator.recommendations.append("‚ö†Ô∏è √áalƒ±≈üma s√ºrenin azalt ve d√ºzenli molalar ver.")
        elif risk_score >= 30:
            indicator.overall_risk = BurnoutRisk.MODERATE
            indicator.recommendations.append("üí° Dikkatli ol, √ßalƒ±≈üma-dinlenme dengesini koru.")
        else:
            indicator.overall_risk = BurnoutRisk.LOW
            indicator.recommendations.append("‚úÖ Dengeli gidiyorsun, b√∂yle devam et!")
        
        # Kaydet
        if user_id not in self.indicators:
            self.indicators[user_id] = []
        self.indicators[user_id].append(indicator)
        
        return indicator
    
    def get_burnout_dashboard(self, user_id: str) -> Dict[str, Any]:
        """T√ºkenmi≈ülik dashboard"""
        indicators = self.indicators.get(user_id, [])
        
        if not indicators:
            return {"has_data": False, "risk": "unknown"}
        
        latest = indicators[-1]
        
        # Trend (son 4 deƒüerlendirme)
        recent_scores = [i.risk_score for i in indicators[-4:]]
        trend = TrendDirection.STABLE
        if len(recent_scores) >= 2:
            if recent_scores[-1] > recent_scores[0] * 1.2:
                trend = TrendDirection.DECLINING  # Risk artƒ±yor
            elif recent_scores[-1] < recent_scores[0] * 0.8:
                trend = TrendDirection.IMPROVING
        
        return {
            "has_data": True,
            "current_risk": latest.overall_risk.value,
            "risk_score": latest.risk_score,
            "factors": {
                "overwork": latest.overwork_score,
                "fatigue": latest.fatigue_score,
                "performance_drop": latest.declining_performance,
                "schedule_irregularity": latest.irregular_schedule
            },
            "trend": trend.value,
            "warnings": latest.warnings,
            "recommendations": latest.recommendations
        }


class ExamPredictionEngine:
    """Sƒ±nav puanƒ± tahmin engine'i"""
    
    def __init__(self):
        self.predictions: Dict[str, List[ExamScorePrediction]] = {}
        self.strength_engine = StrengthMapEngine()
    
    def predict_score(self, user_id: str,
                     topics: List[str],
                     topic_strengths: Dict[str, float],
                     exam_type: str = "general") -> ExamScorePrediction:
        """Sƒ±nav puanƒ± tahmin et"""
        prediction = ExamScorePrediction(
            topics=topics,
            exam_type=exam_type
        )
        
        if not topic_strengths:
            prediction.predicted_score = 50  # Varsayƒ±lan
            prediction.confidence_level = 0.2
            return prediction
        
        # Topic aƒüƒ±rlƒ±klarƒ± (e≈üit aƒüƒ±rlƒ±k varsayƒ±mƒ±)
        weights = {t: 1.0 / len(topics) for t in topics}
        
        # Aƒüƒ±rlƒ±klƒ± ortalama
        total_score = 0
        for topic in topics:
            strength = topic_strengths.get(topic, 50)
            prediction.topic_predictions[topic] = strength
            total_score += strength * weights[topic]
        
        prediction.predicted_score = total_score
        
        # G√ºven aralƒ±ƒüƒ± (standart sapma bazlƒ±)
        scores = list(topic_strengths.values())
        if len(scores) > 1:
            std_dev = statistics.stdev(scores)
            prediction.confidence_interval = (
                max(0, total_score - std_dev),
                min(100, total_score + std_dev)
            )
        else:
            prediction.confidence_interval = (total_score - 10, total_score + 10)
        
        # Confidence level (veri miktarƒ±na baƒülƒ±)
        prediction.confidence_level = min(0.9, 0.3 + len(topic_strengths) * 0.1)
        
        # G√º√ßl√º ve zayƒ±f konular
        sorted_topics = sorted(topic_strengths.items(), key=lambda x: x[1], reverse=True)
        prediction.strong_topics = [t[0] for t in sorted_topics[:3] if t[1] >= 70]
        prediction.weak_topics = [t[0] for t in sorted_topics[-3:] if t[1] < 60]
        
        # √áalƒ±≈üma √∂ncelikleri (en zayƒ±f konular)
        prediction.study_priorities = prediction.weak_topics[:3]
        
        # Tahmini iyile≈ütirme
        for weak_topic in prediction.weak_topics:
            current = topic_strengths.get(weak_topic, 50)
            potential_gain = (80 - current) * 0.5  # %50'sini kazanabilir
            prediction.estimated_improvement[weak_topic] = potential_gain
        
        # Kaydet
        if user_id not in self.predictions:
            self.predictions[user_id] = []
        self.predictions[user_id].append(prediction)
        
        return prediction
    
    def get_prediction_analysis(self, user_id: str) -> Dict[str, Any]:
        """Tahmin analizi"""
        predictions = self.predictions.get(user_id, [])
        
        if not predictions:
            return {"has_predictions": False}
        
        latest = predictions[-1]
        
        return {
            "has_predictions": True,
            "current_prediction": {
                "score": latest.predicted_score,
                "confidence_interval": list(latest.confidence_interval),
                "confidence_level": latest.confidence_level
            },
            "topic_breakdown": latest.topic_predictions,
            "strong_topics": latest.strong_topics,
            "weak_topics": latest.weak_topics,
            "study_priorities": latest.study_priorities,
            "potential_improvement": latest.estimated_improvement,
            "recommendation": self._get_score_recommendation(latest.predicted_score)
        }
    
    def _get_score_recommendation(self, score: float) -> str:
        """Puana g√∂re √∂neri"""
        if score >= 90:
            return "üåü M√ºkemmel hazƒ±rlƒ±k! Sƒ±nava g√ºvenle girebilirsin."
        elif score >= 80:
            return "üëç ƒ∞yi durumdasƒ±n, son tekrarlarla daha da g√º√ßlendir."
        elif score >= 70:
            return "üìö Orta seviye, zayƒ±f konulara odaklan."
        elif score >= 60:
            return "‚ö†Ô∏è Risk b√∂lgesi, yoƒüun √ßalƒ±≈üma gerekli."
        else:
            return "üö® Acil aksiyon al, temel konularƒ± ba≈ütan g√∂zden ge√ßir."


# ============ SINGLETON INSTANCES ============

learning_velocity_engine = LearningVelocityEngine()
strength_map_engine = StrengthMapEngine()
time_roi_engine = TimeROIEngine()
study_plan_engine = StudyPlanEngine()
burnout_detector_engine = BurnoutDetectorEngine()
exam_prediction_engine = ExamPredictionEngine()
