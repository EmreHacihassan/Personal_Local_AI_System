"""
ğŸ§  Chain-of-Thought Reasoning Engine
=====================================

Premium dÃ¼ÅŸÃ¼nme motoru:
- AdÄ±m adÄ±m dÃ¼ÅŸÃ¼nme (CoT)
- Self-consistency checking
- Thought decomposition
- Reasoning traces

Author: Enterprise AI Team
Version: 1.0.0
"""

import re
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum

logger = logging.getLogger(__name__)


# ============================================================================
# ENUMS & DATA CLASSES
# ============================================================================

class ReasoningStrategy(str, Enum):
    """DÃ¼ÅŸÃ¼nme stratejileri."""
    ZERO_SHOT = "zero_shot"           # Direkt yanÄ±t
    FEW_SHOT = "few_shot"             # Ã–rneklerle
    CHAIN_OF_THOUGHT = "cot"          # AdÄ±m adÄ±m
    STRUCTURED = "structured"          # YapÄ±landÄ±rÄ±lmÄ±ÅŸ
    SELF_CONSISTENCY = "self_consistency"  # Ã‡oklu yanÄ±t + oylama


@dataclass
class ThinkingStep:
    """Tek bir dÃ¼ÅŸÃ¼nme adÄ±mÄ±."""
    step_number: int
    description: str
    content: str
    confidence: float = 0.8


@dataclass
class ReasoningResult:
    """DÃ¼ÅŸÃ¼nme sonucu."""
    strategy: ReasoningStrategy
    thinking_steps: List[ThinkingStep]
    final_answer: str
    confidence: float
    reasoning_trace: str
    tokens_used: int = 0


# ============================================================================
# COT TEMPLATES
# ============================================================================

class CoTTemplates:
    """Chain-of-Thought prompt ÅŸablonlarÄ±."""
    
    # Genel CoT ÅŸablonu
    GENERAL_COT = """
YanÄ±t vermeden Ã¶nce adÄ±m adÄ±m dÃ¼ÅŸÃ¼n:

<thinking>
**AdÄ±m 1: Soruyu Analiz Et**
- Soru ne soruyor?
- Anahtar kavramlar neler?
- Ne tÃ¼r bir yanÄ±t bekleniyor?

**AdÄ±m 2: Bilgi Toplama**
- Bu konuda ne biliyorum?
- Hangi kaynaklar kullanÄ±labilir?
- Eksik bilgi var mÄ±?

**AdÄ±m 3: Ã‡Ã¶zÃ¼m PlanÄ±**
- NasÄ±l yaklaÅŸmalÄ±yÄ±m?
- Hangi adÄ±mlarÄ± izlemeliyim?
- OlasÄ± zorluklar neler?

**AdÄ±m 4: Uygulama**
- PlanÄ± adÄ±m adÄ±m uygula
- Her adÄ±mÄ± kontrol et
- SonuÃ§larÄ± deÄŸerlendir

**AdÄ±m 5: DoÄŸrulama**
- YanÄ±t soruyu karÅŸÄ±lÄ±yor mu?
- MantÄ±ksal tutarlÄ±lÄ±k var mÄ±?
- Eksik bir ÅŸey var mÄ±?
</thinking>

<answer>
[YANITINIZ]
</answer>
"""
    
    # Analiz sorularÄ± iÃ§in
    ANALYTICAL_COT = """
Bu analitik soru iÃ§in sistematik dÃ¼ÅŸÃ¼n:

<thinking>
**1. Problem TanÄ±mlama**
- Ana problem: [tanÄ±mla]
- Alt problemler: [listele]
- KÄ±sÄ±tlar: [belirt]

**2. Veri/Bilgi DeÄŸerlendirmesi**
- Mevcut veriler: [listele]
- Eksik bilgiler: [belirt]
- VarsayÄ±mlar: [listele]

**3. Analiz YÃ¶ntemi**
- YaklaÅŸÄ±m: [seÃ§]
- AdÄ±mlar: [planla]
- Metrikler: [belirle]

**4. Uygulama**
[adÄ±m adÄ±m analiz]

**5. SonuÃ§ ve Ã–neriler**
- Bulgular: [Ã¶zetle]
- Ã–neriler: [listele]
- Limitasyonlar: [belirt]
</thinking>

<answer>
[ANALÄ°Z SONUCU]
</answer>
"""
    
    # KarÅŸÄ±laÅŸtÄ±rma sorularÄ± iÃ§in
    COMPARISON_COT = """
KarÅŸÄ±laÅŸtÄ±rma iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ dÃ¼ÅŸÃ¼n:

<thinking>
**1. KarÅŸÄ±laÅŸtÄ±rÄ±lacaklar**
- A: [tanÄ±mla]
- B: [tanÄ±mla]
- KarÅŸÄ±laÅŸtÄ±rma kriterleri: [listele]

**2. Kriter BazlÄ± Analiz**
| Kriter | A | B | Kazanan |
|--------|---|---|---------|
| [kriter1] | [deÄŸer] | [deÄŸer] | [A/B/EÅŸit] |
| [kriter2] | [deÄŸer] | [deÄŸer] | [A/B/EÅŸit] |

**3. Avantaj/Dezavantajlar**
A: 
+ [avantaj]
- [dezavantaj]

B:
+ [avantaj]
- [dezavantaj]

**4. BaÄŸlama GÃ¶re SeÃ§im**
- [durum1] iÃ§in: [Ã¶neri]
- [durum2] iÃ§in: [Ã¶neri]
</thinking>

<answer>
[KARÅILAÅTIRMA SONUCU]
</answer>
"""
    
    # Kod sorularÄ± iÃ§in
    CODING_COT = """
Kod Ã§Ã¶zÃ¼mÃ¼ iÃ§in sistematik dÃ¼ÅŸÃ¼n:

<thinking>
**1. Gereksinim Analizi**
- Girdi: [tanÄ±mla]
- Ã‡Ä±ktÄ±: [tanÄ±mla]
- KÄ±sÄ±tlar: [listele]
- Edge case'ler: [listele]

**2. Algoritma TasarÄ±mÄ±**
- YaklaÅŸÄ±m: [seÃ§]
- Zaman karmaÅŸÄ±klÄ±ÄŸÄ±: O(?)
- Alan karmaÅŸÄ±klÄ±ÄŸÄ±: O(?)
- Pseudo-kod:
  1. [adÄ±m]
  2. [adÄ±m]

**3. Ä°mplementasyon NotlarÄ±**
- Dil: [seÃ§]
- KÃ¼tÃ¼phaneler: [listele]
- Dikkat edilecekler: [listele]

**4. Test SenaryolarÄ±**
- Normal case: [input] â†’ [expected]
- Edge case: [input] â†’ [expected]
- Error case: [input] â†’ [expected]
</thinking>

<answer>
[KOD Ã‡Ã–ZÃœMÃœ]
</answer>
"""
    
    # Matematiksel sorular iÃ§in
    MATH_COT = """
Matematiksel problem iÃ§in adÄ±m adÄ±m Ã§Ã¶z:

<thinking>
**1. Problem Anlama**
- Verilenler: [listele]
- Ä°stenenler: [belirt]
- FormÃ¼ller: [ilgili formÃ¼ller]

**2. Ã‡Ã¶zÃ¼m Stratejisi**
- YÃ¶ntem: [seÃ§]
- AdÄ±mlar: [planla]

**3. Hesaplama**
[adÄ±m adÄ±m hesaplama, her adÄ±mÄ± gÃ¶ster]

**4. DoÄŸrulama**
- SonuÃ§ mantÄ±klÄ± mÄ±?
- Birim kontrolÃ¼: [kontrol et]
- Alternatif yÃ¶ntem: [varsa doÄŸrula]
</thinking>

<answer>
[MATEMATÄ°KSEL SONUÃ‡]
</answer>
"""


# ============================================================================
# COT ENGINE
# ============================================================================

class ChainOfThoughtEngine:
    """
    Chain-of-Thought dÃ¼ÅŸÃ¼nme motoru.
    
    Features:
    - Otomatik CoT ÅŸablon seÃ§imi
    - DÃ¼ÅŸÃ¼nme adÄ±mlarÄ±nÄ± parse etme
    - Confidence hesaplama
    - Reasoning trace oluÅŸturma
    """
    
    # Sorgu tipi -> CoT ÅŸablonu mapping
    TEMPLATE_MAP = {
        "analytical": CoTTemplates.ANALYTICAL_COT,
        "comparison": CoTTemplates.COMPARISON_COT,
        "coding": CoTTemplates.CODING_COT,
        "math": CoTTemplates.MATH_COT,
        "general": CoTTemplates.GENERAL_COT,
    }
    
    # CoT gerektiren keyword'ler
    COT_TRIGGER_KEYWORDS = {
        "analytical": ["analiz", "analyze", "deÄŸerlendir", "evaluate", "incele"],
        "comparison": ["karÅŸÄ±laÅŸtÄ±r", "compare", "fark", "difference", "vs", "versus"],
        "coding": ["kod", "code", "fonksiyon", "function", "algoritma", "algorithm"],
        "math": ["hesapla", "calculate", "formÃ¼l", "formula", "matematiksel", "mathematical"],
        "reasoning": ["neden", "why", "nasÄ±l", "how", "aÃ§Ä±kla", "explain", "sebep", "reason"],
    }
    
    def __init__(self):
        self.templates = CoTTemplates()
    
    def should_use_cot(self, query: str, complexity: str = "normal") -> bool:
        """
        Bu sorgu iÃ§in CoT kullanÄ±lmalÄ± mÄ±?
        
        Args:
            query: KullanÄ±cÄ± sorusu
            complexity: KarmaÅŸÄ±klÄ±k seviyesi
            
        Returns:
            CoT kullanÄ±lmalÄ± mÄ±
        """
        query_lower = query.lower()
        
        # Basit sorgular iÃ§in CoT gereksiz
        if complexity == "simple" or len(query.split()) <= 5:
            return False
        
        # KarmaÅŸÄ±k sorgular iÃ§in her zaman
        if complexity in ["comprehensive", "research"]:
            return True
        
        # Trigger keyword varsa
        for category, keywords in self.COT_TRIGGER_KEYWORDS.items():
            if any(kw in query_lower for kw in keywords):
                return True
        
        return False
    
    def select_template(self, query: str) -> str:
        """
        Sorgu iÃ§in uygun CoT ÅŸablonunu seÃ§.
        
        Args:
            query: KullanÄ±cÄ± sorusu
            
        Returns:
            CoT ÅŸablonu
        """
        query_lower = query.lower()
        
        # SÄ±rayla kontrol et
        if any(kw in query_lower for kw in self.COT_TRIGGER_KEYWORDS["coding"]):
            return self.TEMPLATE_MAP["coding"]
        
        if any(kw in query_lower for kw in self.COT_TRIGGER_KEYWORDS["math"]):
            return self.TEMPLATE_MAP["math"]
        
        if any(kw in query_lower for kw in self.COT_TRIGGER_KEYWORDS["comparison"]):
            return self.TEMPLATE_MAP["comparison"]
        
        if any(kw in query_lower for kw in self.COT_TRIGGER_KEYWORDS["analytical"]):
            return self.TEMPLATE_MAP["analytical"]
        
        return self.TEMPLATE_MAP["general"]
    
    def inject_cot(self, system_prompt: str, query: str) -> str:
        """
        System prompt'a CoT talimatÄ± ekle.
        
        Args:
            system_prompt: Mevcut system prompt
            query: KullanÄ±cÄ± sorusu
            
        Returns:
            CoT eklenmiÅŸ system prompt
        """
        template = self.select_template(query)
        
        return f"{system_prompt}\n\n{template}"
    
    def parse_thinking(self, response: str) -> Tuple[str, str]:
        """
        YanÄ±ttan thinking ve answer kÄ±sÄ±mlarÄ±nÄ± ayÄ±r.
        
        Args:
            response: LLM yanÄ±tÄ±
            
        Returns:
            (thinking_content, answer_content)
        """
        # <thinking>...</thinking> ve <answer>...</answer> pattern'leri
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', response, re.DOTALL)
        answer_match = re.search(r'<answer>(.*?)</answer>', response, re.DOTALL)
        
        thinking = thinking_match.group(1).strip() if thinking_match else ""
        answer = answer_match.group(1).strip() if answer_match else response
        
        # EÄŸer answer bulunamadÄ±ysa, thinking'i Ã§Ä±kar ve kalanÄ± al
        if not answer_match and thinking_match:
            answer = re.sub(r'<thinking>.*?</thinking>', '', response, flags=re.DOTALL).strip()
        
        return thinking, answer
    
    def extract_steps(self, thinking: str) -> List[ThinkingStep]:
        """
        DÃ¼ÅŸÃ¼nme iÃ§eriÄŸinden adÄ±mlarÄ± Ã§Ä±kar.
        
        Args:
            thinking: DÃ¼ÅŸÃ¼nme iÃ§eriÄŸi
            
        Returns:
            AdÄ±m listesi
        """
        steps = []
        
        # **AdÄ±m N:** veya **N.** pattern'lerini ara
        step_patterns = [
            r'\*\*(?:AdÄ±m\s*)?(\d+)[.:]\s*(.*?)\*\*\s*(.*?)(?=\*\*(?:AdÄ±m\s*)?\d+[.:]|\Z)',
            r'(\d+)\.\s*\*\*(.*?)\*\*\s*(.*?)(?=\d+\.\s*\*\*|\Z)',
        ]
        
        for pattern in step_patterns:
            matches = re.findall(pattern, thinking, re.DOTALL)
            if matches:
                for match in matches:
                    step_num = int(match[0])
                    description = match[1].strip()
                    content = match[2].strip()
                    
                    steps.append(ThinkingStep(
                        step_number=step_num,
                        description=description,
                        content=content,
                        confidence=0.8
                    ))
                break
        
        # EÄŸer pattern bulunamadÄ±ysa, paragraflarÄ± adÄ±m olarak al
        if not steps:
            paragraphs = [p.strip() for p in thinking.split('\n\n') if p.strip()]
            for i, para in enumerate(paragraphs, 1):
                steps.append(ThinkingStep(
                    step_number=i,
                    description=f"AdÄ±m {i}",
                    content=para,
                    confidence=0.7
                ))
        
        return steps
    
    def calculate_confidence(self, thinking: str, answer: str) -> float:
        """
        YanÄ±t gÃ¼venilirliÄŸini hesapla.
        
        Args:
            thinking: DÃ¼ÅŸÃ¼nme iÃ§eriÄŸi
            answer: YanÄ±t iÃ§eriÄŸi
            
        Returns:
            GÃ¼ven skoru (0-1)
        """
        confidence = 0.5
        
        # Thinking uzunluÄŸu
        if len(thinking) > 500:
            confidence += 0.1
        if len(thinking) > 1000:
            confidence += 0.1
        
        # AdÄ±m sayÄ±sÄ±
        step_count = len(re.findall(r'\*\*(?:AdÄ±m\s*)?\d+[.:]', thinking))
        if step_count >= 3:
            confidence += 0.1
        if step_count >= 5:
            confidence += 0.05
        
        # Belirsizlik ifadeleri
        uncertainty_words = ["belki", "muhtemelen", "olabilir", "sanÄ±rÄ±m", "maybe", "probably"]
        uncertainty_count = sum(1 for word in uncertainty_words if word in answer.lower())
        confidence -= uncertainty_count * 0.05
        
        # Kaynak referanslarÄ±
        if re.search(r'\[Kaynak|\[Source', answer):
            confidence += 0.1
        
        return max(0.1, min(1.0, confidence))
    
    def process_response(self, response: str, query: str) -> ReasoningResult:
        """
        LLM yanÄ±tÄ±nÄ± iÅŸle ve reasoning result oluÅŸtur.
        
        Args:
            response: LLM yanÄ±tÄ±
            query: Orijinal sorgu
            
        Returns:
            ReasoningResult
        """
        thinking, answer = self.parse_thinking(response)
        steps = self.extract_steps(thinking) if thinking else []
        confidence = self.calculate_confidence(thinking, answer)
        
        return ReasoningResult(
            strategy=ReasoningStrategy.CHAIN_OF_THOUGHT if thinking else ReasoningStrategy.ZERO_SHOT,
            thinking_steps=steps,
            final_answer=answer,
            confidence=confidence,
            reasoning_trace=thinking,
        )


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

cot_engine = ChainOfThoughtEngine()


__all__ = [
    "ChainOfThoughtEngine",
    "CoTTemplates",
    "ReasoningStrategy",
    "ReasoningResult",
    "ThinkingStep",
    "cot_engine",
]
