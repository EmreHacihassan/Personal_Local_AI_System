"""
DeepScholar v2.0 - Fraktal AraÅŸtÄ±rma ve Sentez Mimarisi
=======================================================

Kurumsal seviye akademik dÃ¶kÃ¼man oluÅŸturucu.

Ã–zellikler:
- Fraktal GeniÅŸleme (Fractal Expansion) - Dinamik derinlik yÃ¶netimi
- Global/Local State yÃ¶netimi - TutarlÄ±lÄ±k iÃ§in hafÄ±za mimarisi
- Information Gain algoritmasÄ± - AkÄ±llÄ± araÅŸtÄ±rma derinliÄŸi
- Cross-Pollination sentez motoru - Kaynak sentezleme
- Self-Correction dÃ¶ngÃ¼sÃ¼ - HalÃ¼sinasyon kontrolÃ¼
- User Proxy simÃ¼latÃ¶rÃ¼ - Ä°Ã§ kalite kontrolÃ¼
- Paralel araÅŸtÄ±rma + SÄ±ralÄ± yazÄ±m
- Akademik kaynakÃ§a (APA/IEEE/Chicago)
- PDF export
- Ã‡oklu dil desteÄŸi
- CanlÄ± ilerleme takibi (WebSocket)

Maksimum: 60 sayfa
"""

import asyncio
import json
import time
import hashlib
import re
from typing import Optional, List, Dict, Any, AsyncGenerator, Callable, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
import traceback

from core.config import settings
from core.llm_manager import llm_manager

# Premium modÃ¼ller (opsiyonel)
try:
    from core.deep_scholar_premium.advanced import (
        DynamicPageManager,
        MultiAgentDebate,
        RealTimeStreamingManager,
        OriginalityChecker,
        MultilingualResearchEngine,
        ResearchAnalyticsEngine,
        LiteratureReviewEngine,
        PRISMAGenerator
    )
    PREMIUM_ADVANCED_AVAILABLE = True
except ImportError:
    PREMIUM_ADVANCED_AVAILABLE = False


# ============================================================================
# ENUMS & CONSTANTS
# ============================================================================

class DocumentLanguage(str, Enum):
    """Desteklenen dÃ¶kÃ¼man dilleri."""
    TURKISH = "tr"
    ENGLISH = "en"
    GERMAN = "de"


class CitationStyle(str, Enum):
    """KaynakÃ§a stilleri."""
    APA = "apa"
    IEEE = "ieee"
    CHICAGO = "chicago"
    HARVARD = "harvard"


class ResearchDepth(str, Enum):
    """AraÅŸtÄ±rma derinliÄŸi."""
    SHALLOW = "shallow"      # 1-5 sayfa: YÃ¼zeysel Ã¶zet
    MODERATE = "moderate"    # 6-15 sayfa: Orta detay
    DEEP = "deep"           # 16-30 sayfa: Derin araÅŸtÄ±rma
    EXHAUSTIVE = "exhaustive"  # 31-60 sayfa: KapsamlÄ± analiz


class AgentRole(str, Enum):
    """Ajan rolleri."""
    ORCHESTRATOR = "orchestrator"
    PLANNER = "planner"
    RESEARCHER = "researcher"
    WRITER = "writer"
    FACT_CHECKER = "fact_checker"
    USER_PROXY = "user_proxy"
    SYNTHESIZER = "synthesizer"


class EventType(str, Enum):
    """WebSocket event tipleri."""
    PHASE_START = "phase_start"
    PHASE_END = "phase_end"
    AGENT_MESSAGE = "agent_message"
    RESEARCH_FOUND = "research_found"
    SECTION_START = "section_start"
    SECTION_COMPLETE = "section_complete"
    CONFLICT_DETECTED = "conflict_detected"
    FACT_CHECK = "fact_check"
    USER_PROXY_FEEDBACK = "user_proxy_feedback"
    PROGRESS = "progress"
    ERROR = "error"
    COMPLETE = "complete"
    # Yeni event tipleri
    PAUSED = "paused"
    RESUMED = "resumed"
    VISUAL_GENERATED = "visual_generated"
    CHECKPOINT_SAVED = "checkpoint_saved"


class VisualType(str, Enum):
    """GÃ¶rsel tipleri."""
    MERMAID_FLOWCHART = "mermaid_flowchart"
    MERMAID_SEQUENCE = "mermaid_sequence"
    MERMAID_MINDMAP = "mermaid_mindmap"
    MERMAID_TIMELINE = "mermaid_timeline"
    MERMAID_PIE = "mermaid_pie"
    MERMAID_GANTT = "mermaid_gantt"
    ASCII_TABLE = "ascii_table"
    ASCII_CHART = "ascii_chart"
    LATEX_FORMULA = "latex_formula"
    CODE_BLOCK = "code_block"
    COMPARISON_TABLE = "comparison_table"
    STATISTICS_BOX = "statistics_box"


# ============================================================================
# DATA CLASSES
# ============================================================================

@dataclass
class Citation:
    """Akademik atÄ±f."""
    id: str
    source_type: str  # web, pdf, article, book
    title: str
    authors: List[str] = field(default_factory=list)
    year: Optional[int] = None
    url: Optional[str] = None
    doi: Optional[str] = None
    journal: Optional[str] = None
    publisher: Optional[str] = None
    pages: Optional[str] = None
    access_date: Optional[str] = None
    
    # DÃ¶kÃ¼man iÃ§i kullanÄ±m
    used_in_pages: List[int] = field(default_factory=list)
    used_in_sections: List[str] = field(default_factory=list)
    inline_citations: List[Dict] = field(default_factory=list)  # {page, line, text}
    
    def to_apa(self) -> str:
        """APA formatÄ±nda kaynakÃ§a."""
        authors_str = ", ".join(self.authors) if self.authors else "Unknown"
        year_str = f"({self.year})" if self.year else "(n.d.)"
        
        if self.url:
            return f"{authors_str} {year_str}. {self.title}. Retrieved from {self.url}"
        elif self.journal:
            return f"{authors_str} {year_str}. {self.title}. {self.journal}, {self.pages or ''}."
        else:
            return f"{authors_str} {year_str}. {self.title}. {self.publisher or ''}."
    
    def to_ieee(self) -> str:
        """IEEE formatÄ±nda kaynakÃ§a."""
        authors_str = ", ".join(self.authors) if self.authors else "Unknown"
        
        if self.journal:
            return f'{authors_str}, "{self.title}," {self.journal}, {self.year or "n.d."}.'
        elif self.url:
            return f'{authors_str}, "{self.title}," [Online]. Available: {self.url}'
        else:
            return f'{authors_str}, "{self.title}," {self.publisher or ""}, {self.year or "n.d."}.'
    
    def to_chicago(self) -> str:
        """Chicago formatÄ±nda kaynakÃ§a."""
        authors_str = ", ".join(self.authors) if self.authors else "Unknown"
        
        if self.journal:
            return f'{authors_str}. "{self.title}." {self.journal} ({self.year or "n.d."}): {self.pages or ""}.'
        else:
            return f'{authors_str}. {self.title}. {self.publisher or ""}, {self.year or "n.d."}.'


@dataclass
class ResearchItem:
    """AraÅŸtÄ±rma sonucu."""
    id: str
    content: str
    source_title: str
    source_url: Optional[str] = None
    source_type: str = "web"  # web, pdf, academic, local
    relevance_score: float = 0.0
    reliability_score: float = 0.5
    authors: List[str] = field(default_factory=list)
    year: Optional[int] = None
    abstract: Optional[str] = None
    keywords: List[str] = field(default_factory=list)
    claims: List[str] = field(default_factory=list)  # Ã‡Ä±karÄ±lan iddialar
    evidence: List[str] = field(default_factory=list)  # KanÄ±tlar


@dataclass
class SectionOutline:
    """BÃ¶lÃ¼m taslaÄŸÄ±."""
    id: str
    title: str
    level: int  # 1 = ana bÃ¶lÃ¼m, 2 = alt bÃ¶lÃ¼m, 3 = alt-alt
    page_start: int
    page_end: int
    word_target: int
    subtopics: List[str] = field(default_factory=list)
    key_points: List[str] = field(default_factory=list)
    research_queries: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)  # BaÄŸÄ±mlÄ± olduÄŸu bÃ¶lÃ¼mler
    parent_id: Optional[str] = None


@dataclass
class GlobalState:
    """
    Global State (Uzun SÃ¼reli HafÄ±za)
    TÃ¼m ajanlar tarafÄ±ndan okunabilir, sadece Orchestrator tarafÄ±ndan deÄŸiÅŸtirilebilir.
    """
    # Master plan
    master_outline: List[SectionOutline] = field(default_factory=list)
    thesis_statement: str = ""
    
    # TutarlÄ±lÄ±k iÃ§in
    global_glossary: Dict[str, str] = field(default_factory=dict)  # Terim -> AÃ§Ä±klama
    style_guide: Dict[str, str] = field(default_factory=dict)
    
    # Kaynaklar
    all_citations: Dict[str, Citation] = field(default_factory=dict)  # id -> Citation
    citation_counter: int = 0
    
    # Ãœst bilgi
    document_title: str = ""
    document_topic: str = ""
    target_pages: int = 10
    language: DocumentLanguage = DocumentLanguage.TURKISH
    citation_style: CitationStyle = CitationStyle.APA
    
    # YazÄ±m tamamlanan bÃ¶lÃ¼mler
    completed_sections: Dict[str, str] = field(default_factory=dict)  # section_id -> content
    section_summaries: Dict[str, str] = field(default_factory=dict)  # section_id -> summary


@dataclass
class LocalState:
    """
    Local State (KÄ±sa SÃ¼reli HafÄ±za)
    Sadece aktif bÃ¶lÃ¼mÃ¼ ilgilendirir, bÃ¶lÃ¼m bitince temizlenir.
    """
    current_section: Optional[SectionOutline] = None
    current_sources: List[ResearchItem] = field(default_factory=list)
    previous_section_summary: str = ""
    current_content: str = ""
    current_word_count: int = 0
    
    # Sentez iÃ§in
    extracted_claims: List[Dict] = field(default_factory=list)
    detected_conflicts: List[Dict] = field(default_factory=list)
    
    def clear(self):
        """BÃ¶lÃ¼m tamamlandÄ±ÄŸÄ±nda temizle."""
        self.current_section = None
        self.current_sources = []
        self.current_content = ""
        self.current_word_count = 0
        self.extracted_claims = []
        self.detected_conflicts = []


@dataclass
class AgentMessage:
    """Ajanlar arasÄ± mesaj."""
    from_agent: AgentRole
    to_agent: AgentRole
    message_type: str
    content: Dict[str, Any]
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class DeepScholarConfig:
    """DeepScholar yapÄ±landÄ±rmasÄ±."""
    title: str
    topic: str
    page_count: int = 10
    language: DocumentLanguage = DocumentLanguage.TURKISH
    citation_style: CitationStyle = CitationStyle.APA
    style: str = "academic"  # academic, casual, detailed, summary, exam_prep
    
    # AraÅŸtÄ±rma ayarlarÄ±
    web_search: str = "auto"  # off, auto, on
    academic_search: bool = True
    max_sources_per_section: int = 10
    
    # Kalite ayarlarÄ±
    enable_fact_checking: bool = True
    enable_user_proxy: bool = True
    enable_conflict_detection: bool = True
    
    # KullanÄ±cÄ± talimatlarÄ±
    custom_instructions: str = ""
    user_persona: str = ""  # User Proxy iÃ§in persona
    
    # GeliÅŸmiÅŸ
    parallel_research: bool = True
    max_research_depth: int = 3  # Fraktal derinlik
    
    # GÃ¶rsel Ã¼retim ayarlarÄ± (Premium)
    enable_visuals: bool = True  # GÃ¶rsel Ã¼retimi aktif
    visual_types: List[str] = field(default_factory=lambda: [
        "mermaid_flowchart", "mermaid_mindmap", "ascii_table", 
        "latex_formula", "comparison_table", "statistics_box"
    ])
    visuals_per_section: int = 2  # BÃ¶lÃ¼m baÅŸÄ±na maksimum gÃ¶rsel sayÄ±sÄ±
    enable_code_examples: bool = True  # Kod Ã¶rnekleri ekle
    enable_formulas: bool = True  # Matematiksel formÃ¼ller ekle
    
    # ğŸš€ Premium V2 Ã–zellikler
    enable_dynamic_pages: bool = True  # Dinamik sayfa artÄ±rma (max +15)
    max_page_expansion: int = 15  # Maksimum ek sayfa sayÄ±sÄ±
    enable_debate_mode: bool = False  # Ã‡ok ajanlÄ± tartÄ±ÅŸma modu
    debate_perspectives: List[str] = field(default_factory=lambda: ["pro", "con", "devils_advocate"])
    enable_originality_check: bool = True  # Orijinallik kontrolÃ¼
    enable_multilingual: bool = False  # Ã‡ok dilli araÅŸtÄ±rma
    research_languages: List[str] = field(default_factory=lambda: ["en", "tr"])
    enable_analytics: bool = True  # AraÅŸtÄ±rma analitiÄŸi
    enable_literature_review: bool = False  # Sistematik literatÃ¼r tarama (PRISMA)
    enable_realtime_streaming: bool = True  # GerÃ§ek zamanlÄ± streaming


@dataclass
class GenerationCheckpoint:
    """Ãœretim checkpoint'i - Pause/Resume iÃ§in."""
    document_id: str
    config: Dict[str, Any]
    progress: int
    current_phase: str
    completed_sections: List[Dict[str, Any]]
    pending_sections: List[Dict[str, Any]]
    all_research: Dict[str, List[Dict[str, Any]]]
    global_state: Dict[str, Any]
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def to_dict(self) -> Dict[str, Any]:
        """JSON'a dÃ¶nÃ¼ÅŸtÃ¼r."""
        return {
            "document_id": self.document_id,
            "config": self.config,
            "progress": self.progress,
            "current_phase": self.current_phase,
            "completed_sections": self.completed_sections,
            "pending_sections": self.pending_sections,
            "all_research": self.all_research,
            "global_state": self.global_state,
            "created_at": self.created_at
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'GenerationCheckpoint':
        """JSON'dan oluÅŸtur."""
        return cls(
            document_id=data["document_id"],
            config=data["config"],
            progress=data["progress"],
            current_phase=data["current_phase"],
            completed_sections=data["completed_sections"],
            pending_sections=data["pending_sections"],
            all_research=data["all_research"],
            global_state=data["global_state"],
            created_at=data.get("created_at", datetime.now().isoformat())
        )


# ============================================================================
# ACADEMIC SEARCH ENGINE
# ============================================================================

class AcademicSearchEngine:
    """
    Ãœcretsiz akademik arama motoru.
    
    Desteklenen kaynaklar:
    - Semantic Scholar API (Ã¼cretsiz)
    - arXiv API (Ã¼cretsiz)
    - CrossRef API (Ã¼cretsiz)
    - CORE API (Ã¼cretsiz)
    - OpenAlex API (Ã¼cretsiz)
    """
    
    def __init__(self):
        self.semantic_scholar_base = "https://api.semanticscholar.org/graph/v1"
        self.arxiv_base = "http://export.arxiv.org/api/query"
        self.crossref_base = "https://api.crossref.org/works"
        self.openalex_base = "https://api.openalex.org"
        
    async def search_semantic_scholar(
        self, 
        query: str, 
        limit: int = 10
    ) -> List[ResearchItem]:
        """Semantic Scholar'da arama."""
        import aiohttp
        
        results = []
        try:
            async with aiohttp.ClientSession() as session:
                url = f"{self.semantic_scholar_base}/paper/search"
                params = {
                    "query": query,
                    "limit": limit,
                    "fields": "title,abstract,authors,year,url,citationCount,journal"
                }
                
                async with session.get(url, params=params, timeout=30) as response:
                    if response.status == 200:
                        data = await response.json()
                        for paper in data.get("data", []):
                            authors = [a.get("name", "") for a in paper.get("authors", [])]
                            results.append(ResearchItem(
                                id=f"ss_{paper.get('paperId', '')}",
                                content=paper.get("abstract", "") or "",
                                source_title=paper.get("title", ""),
                                source_url=paper.get("url"),
                                source_type="academic",
                                authors=authors,
                                year=paper.get("year"),
                                abstract=paper.get("abstract"),
                                relevance_score=min(paper.get("citationCount", 0) / 100, 1.0),
                                reliability_score=0.9  # Akademik kaynak
                            ))
        except Exception as e:
            print(f"[Semantic Scholar Error] {e}")
        
        return results
    
    async def search_arxiv(
        self, 
        query: str, 
        limit: int = 10
    ) -> List[ResearchItem]:
        """arXiv'de arama."""
        import aiohttp
        import xml.etree.ElementTree as ET
        
        results = []
        try:
            async with aiohttp.ClientSession() as session:
                params = {
                    "search_query": f"all:{query}",
                    "start": 0,
                    "max_results": limit,
                    "sortBy": "relevance"
                }
                
                async with session.get(self.arxiv_base, params=params, timeout=30) as response:
                    if response.status == 200:
                        text = await response.text()
                        root = ET.fromstring(text)
                        
                        ns = {"atom": "http://www.w3.org/2005/Atom"}
                        
                        for entry in root.findall("atom:entry", ns):
                            title = entry.find("atom:title", ns)
                            summary = entry.find("atom:summary", ns)
                            published = entry.find("atom:published", ns)
                            link = entry.find("atom:id", ns)
                            
                            authors = []
                            for author in entry.findall("atom:author", ns):
                                name = author.find("atom:name", ns)
                                if name is not None:
                                    authors.append(name.text)
                            
                            year = None
                            if published is not None and published.text:
                                year = int(published.text[:4])
                            
                            results.append(ResearchItem(
                                id=f"arxiv_{hashlib.md5((link.text or '').encode()).hexdigest()[:8]}",
                                content=summary.text if summary is not None else "",
                                source_title=title.text if title is not None else "",
                                source_url=link.text if link is not None else None,
                                source_type="academic",
                                authors=authors,
                                year=year,
                                abstract=summary.text if summary is not None else None,
                                relevance_score=0.85,
                                reliability_score=0.9
                            ))
        except Exception as e:
            print(f"[arXiv Error] {e}")
        
        return results
    
    async def search_crossref(
        self, 
        query: str, 
        limit: int = 10
    ) -> List[ResearchItem]:
        """CrossRef'te arama."""
        import aiohttp
        
        results = []
        try:
            async with aiohttp.ClientSession() as session:
                params = {
                    "query": query,
                    "rows": limit,
                    "select": "title,abstract,author,published-print,URL,DOI,container-title"
                }
                
                async with session.get(self.crossref_base, params=params, timeout=30) as response:
                    if response.status == 200:
                        data = await response.json()
                        for item in data.get("message", {}).get("items", []):
                            authors = []
                            for author in item.get("author", []):
                                name = f"{author.get('given', '')} {author.get('family', '')}".strip()
                                if name:
                                    authors.append(name)
                            
                            year = None
                            published = item.get("published-print", {}).get("date-parts", [[]])
                            if published and published[0]:
                                year = published[0][0]
                            
                            title = item.get("title", [""])[0] if item.get("title") else ""
                            
                            results.append(ResearchItem(
                                id=f"cr_{item.get('DOI', hashlib.md5(title.encode()).hexdigest()[:8])}",
                                content=item.get("abstract", "") or "",
                                source_title=title,
                                source_url=item.get("URL"),
                                source_type="academic",
                                authors=authors,
                                year=year,
                                abstract=item.get("abstract"),
                                relevance_score=0.8,
                                reliability_score=0.85
                            ))
        except Exception as e:
            print(f"[CrossRef Error] {e}")
        
        return results
    
    async def search_all(
        self, 
        query: str, 
        limit_per_source: int = 5
    ) -> List[ResearchItem]:
        """TÃ¼m kaynaklarda paralel arama."""
        tasks = [
            self.search_semantic_scholar(query, limit_per_source),
            self.search_arxiv(query, limit_per_source),
            self.search_crossref(query, limit_per_source),
        ]
        
        results_lists = await asyncio.gather(*tasks, return_exceptions=True)
        
        all_results = []
        for results in results_lists:
            if isinstance(results, list):
                all_results.extend(results)
        
        # SÄ±rala ve deduplicate
        seen_titles = set()
        unique_results = []
        for r in sorted(all_results, key=lambda x: x.relevance_score, reverse=True):
            title_lower = r.source_title.lower()
            if title_lower not in seen_titles:
                seen_titles.add(title_lower)
                unique_results.append(r)
        
        return unique_results


# ============================================================================
# WEB SEARCH ENGINE
# ============================================================================

class WebSearchEngine:
    """Web arama motoru wrapper."""
    
    async def search(
        self, 
        query: str, 
        num_results: int = 5
    ) -> List[ResearchItem]:
        """Web'de arama."""
        results = []
        
        try:
            from tools.web_search_engine import PremiumWebSearchEngine
            
            engine = PremiumWebSearchEngine()
            web_result = engine.search(query, num_results=num_results)
            
            if hasattr(web_result, 'results'):
                for wr in web_result.results:
                    content = getattr(wr, 'full_content', None) or getattr(wr, 'snippet', '') or ''
                    
                    results.append(ResearchItem(
                        id=f"web_{hashlib.md5(getattr(wr, 'url', '').encode()).hexdigest()[:8]}",
                        content=content[:2000],
                        source_title=getattr(wr, 'title', '') or 'Web Page',
                        source_url=getattr(wr, 'url', None),
                        source_type="web",
                        relevance_score=getattr(wr, 'relevance_score', 0.7),
                        reliability_score=getattr(wr, 'reliability_score', 0.5)
                    ))
        except Exception as e:
            print(f"[Web Search Error] {e}")
        
        return results


# ============================================================================
# DEEP SCHOLAR AGENTS
# ============================================================================

class BaseAgent:
    """Temel ajan sÄ±nÄ±fÄ±."""
    
    def __init__(self, role: AgentRole, global_state: GlobalState):
        self.role = role
        self.global_state = global_state
        self._executor = ThreadPoolExecutor(max_workers=2)
    
    async def _llm_generate(self, prompt: str, temperature: float = 0.7, timeout: int = 600) -> str:
        """LLM Ã§aÄŸrÄ±sÄ± (async wrapper with timeout).
        
        Args:
            prompt: LLM'e gÃ¶nderilecek prompt
            temperature: YaratÄ±cÄ±lÄ±k seviyesi
            timeout: Maksimum bekleme sÃ¼resi (saniye), varsayÄ±lan 10 dakika (kalite iÃ§in yeterli dÃ¼ÅŸÃ¼nme sÃ¼resi)
        """
        loop = asyncio.get_event_loop()
        try:
            return await asyncio.wait_for(
                loop.run_in_executor(
                    self._executor,
                    lambda: llm_manager.generate(prompt, temperature=temperature)
                ),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            raise TimeoutError(f"LLM Ã§aÄŸrÄ±sÄ± {timeout} saniye iÃ§inde yanÄ±t vermedi")
    
    def _parse_json(self, text: str) -> Any:
        """JSON parse with fallback."""
        try:
            # JSON bloÄŸunu bul
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
            if json_match:
                return json.loads(json_match.group(1))
            
            # Direkt JSON dene
            json_match = re.search(r'[\[\{][\s\S]*[\]\}]', text)
            if json_match:
                return json.loads(json_match.group(0))
            
            return json.loads(text)
        except:
            return None


class PlannerAgent(BaseAgent):
    """
    Planlama AjanÄ±
    
    GÃ¶revler:
    - DÃ¶kÃ¼man iskeletini oluÅŸtur
    - Sayfa daÄŸÄ±lÄ±mÄ±nÄ± hesapla
    - AraÅŸtÄ±rma sorgularÄ±nÄ± belirle
    - Fraktal geniÅŸleme kararlarÄ±
    """
    
    def __init__(self, global_state: GlobalState):
        super().__init__(AgentRole.PLANNER, global_state)
    
    async def create_master_outline(
        self, 
        config: DeepScholarConfig
    ) -> List[SectionOutline]:
        """Ana iÃ§erik planÄ±nÄ± oluÅŸtur."""
        
        # Derinlik hesapla
        if config.page_count <= 5:
            depth = ResearchDepth.SHALLOW
            section_count = 4  # GiriÅŸ, 2 bÃ¶lÃ¼m, SonuÃ§
        elif config.page_count <= 15:
            depth = ResearchDepth.MODERATE
            section_count = 6
        elif config.page_count <= 30:
            depth = ResearchDepth.DEEP
            section_count = 10
        else:
            depth = ResearchDepth.EXHAUSTIVE
            section_count = 15
        
        words_per_page = 400
        total_words = config.page_count * words_per_page
        
        lang_prompts = {
            DocumentLanguage.TURKISH: "TÃ¼rkÃ§e",
            DocumentLanguage.ENGLISH: "English",
            DocumentLanguage.GERMAN: "Deutsch"
        }
        
        prompt = f"""Sen akademik bir dÃ¶kÃ¼man planlayÄ±cÄ±sÄ±sÄ±n. AÅŸaÄŸÄ±daki konu iÃ§in {config.page_count} sayfalÄ±k kapsamlÄ± bir dÃ¶kÃ¼man planÄ± oluÅŸtur.

KONU: {config.topic}
BAÅLIK: {config.title}
DÄ°L: {lang_prompts.get(config.language, 'TÃ¼rkÃ§e')}
ARAÅTIRMA DERÄ°NLÄ°ÄÄ°: {depth.value}
TOPLAM KELÄ°ME HEDEFÄ°: ~{total_words} kelime
TAHMÄ°NÄ° BÃ–LÃœM SAYISI: {section_count}
YAZI STÄ°LÄ°: {config.style}

{f'KULLANICI TALÄ°MATLARI: {config.custom_instructions}' if config.custom_instructions else ''}

Her bÃ¶lÃ¼m iÃ§in ÅŸunlarÄ± planla:
1. BÃ¶lÃ¼m baÅŸlÄ±ÄŸÄ± ve seviyesi (1=ana, 2=alt, 3=alt-alt)
2. Sayfa aralÄ±ÄŸÄ±
3. Kelime hedefi
4. Alt konular
5. AraÅŸtÄ±rÄ±lmasÄ± gereken anahtar noktalar
6. Web/Akademik arama sorgularÄ±
7. BaÄŸÄ±mlÄ± olduÄŸu Ã¶nceki bÃ¶lÃ¼mler

JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
[
  {{
    "id": "sec_1",
    "title": "GiriÅŸ",
    "level": 1,
    "page_start": 1,
    "page_end": 2,
    "word_target": 800,
    "subtopics": ["Konunun Ã¶nemi", "AraÅŸtÄ±rma sorusu"],
    "key_points": ["Ana argÃ¼man", "Kapsam"],
    "research_queries": ["konu genel bakÄ±ÅŸ", "konu tarihÃ§esi"],
    "dependencies": []
  }},
  ...
]
```

Ã–nemli kurallar:
- GiriÅŸ ve SonuÃ§ bÃ¶lÃ¼mleri mutlaka olmalÄ±
- Sayfa daÄŸÄ±lÄ±mÄ± dengeli olmalÄ±
- Toplam {config.page_count} sayfayÄ± geÃ§memeli
- Her bÃ¶lÃ¼m mantÄ±ksal bir akÄ±ÅŸ izlemeli
- AraÅŸtÄ±rma sorgularÄ± spesifik ve aranabilir olmalÄ±"""

        response = await self._llm_generate(prompt)
        
        outline_data = self._parse_json(response)
        
        # Validate outline_data is a list of dicts
        if not outline_data or not isinstance(outline_data, list):
            return self._default_outline(config)
        
        sections = []
        for i, sec in enumerate(outline_data):
            # Skip non-dict elements (e.g., if LLM returns list of strings)
            if not isinstance(sec, dict):
                continue
            sections.append(SectionOutline(
                id=sec.get("id", f"sec_{i+1}"),
                title=sec.get("title", f"BÃ¶lÃ¼m {i+1}"),
                level=sec.get("level", 1),
                page_start=sec.get("page_start", i+1),
                page_end=sec.get("page_end", i+2),
                word_target=sec.get("word_target", 400),
                subtopics=sec.get("subtopics", []),
                key_points=sec.get("key_points", []),
                research_queries=sec.get("research_queries", [config.topic]),
                dependencies=sec.get("dependencies", []),
                parent_id=sec.get("parent_id")
            ))
        
        # If no valid sections found, use default
        if not sections:
            return self._default_outline(config)
        
        return sections
    
    def _default_outline(self, config: DeepScholarConfig) -> List[SectionOutline]:
        """VarsayÄ±lan plan."""
        words_per_page = 400
        total_words = config.page_count * words_per_page
        
        return [
            SectionOutline(
                id="sec_1",
                title="GiriÅŸ" if config.language == DocumentLanguage.TURKISH else "Introduction",
                level=1,
                page_start=1,
                page_end=max(1, config.page_count // 6),
                word_target=total_words // 6,
                subtopics=[config.topic],
                key_points=["Konunun Ã¶nemi", "AraÅŸtÄ±rma sorusu"],
                research_queries=[f"{config.topic} genel bakÄ±ÅŸ", f"{config.topic} tarihÃ§e"]
            ),
            SectionOutline(
                id="sec_2",
                title="Ana Ä°Ã§erik" if config.language == DocumentLanguage.TURKISH else "Main Content",
                level=1,
                page_start=max(1, config.page_count // 6) + 1,
                page_end=config.page_count - max(1, config.page_count // 6),
                word_target=int(total_words * 0.7),
                subtopics=[config.topic],
                key_points=["Temel kavramlar", "DetaylÄ± analiz"],
                research_queries=[config.topic, f"{config.topic} detaylar"]
            ),
            SectionOutline(
                id="sec_3",
                title="SonuÃ§" if config.language == DocumentLanguage.TURKISH else "Conclusion",
                level=1,
                page_start=config.page_count - max(1, config.page_count // 6) + 1,
                page_end=config.page_count,
                word_target=total_words // 6,
                subtopics=["Ã–zet"],
                key_points=["Ana bulgular", "Gelecek Ã§alÄ±ÅŸmalar"],
                research_queries=[]
            )
        ]
    
    async def expand_section(
        self, 
        section: SectionOutline, 
        current_research: List[ResearchItem],
        target_depth: int
    ) -> List[SectionOutline]:
        """
        Fraktal GeniÅŸleme - BÃ¶lÃ¼mÃ¼ alt bÃ¶lÃ¼mlere ayÄ±r.
        
        Information Gain algoritmasÄ±: EÄŸer toplanan veri yeterince zenginse,
        bÃ¶lÃ¼mÃ¼ daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶l.
        """
        if target_depth <= 0:
            return [section]
        
        # Bilgi kazancÄ±nÄ± hesapla
        info_density = len(current_research) * sum(r.relevance_score for r in current_research)
        
        # Yeterli bilgi yoksa geniÅŸleme yapma
        if info_density < 2.0:
            return [section]
        
        prompt = f"""Bu bÃ¶lÃ¼mÃ¼ alt bÃ¶lÃ¼mlere ayÄ±r:

BÃ–LÃœM: {section.title}
ALT KONULAR: {', '.join(section.subtopics)}
KELÄ°ME HEDEFÄ°: {section.word_target}

MEVCUT ARAÅTIRMA KONULARI:
{chr(10).join([f"- {r.source_title}: {r.content[:200]}..." for r in current_research[:5]])}

Bu bÃ¶lÃ¼mÃ¼ 2-4 alt bÃ¶lÃ¼me ayÄ±r. JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
[
  {{"title": "Alt BÃ¶lÃ¼m 1", "key_points": ["..."], "word_target": 200}},
  ...
]
```"""

        response = await self._llm_generate(prompt)
        subsections_data = self._parse_json(response)
        
        if not subsections_data or len(subsections_data) < 2:
            return [section]
        
        # Alt bÃ¶lÃ¼mleri oluÅŸtur
        subsections = []
        word_per_sub = section.word_target // len(subsections_data)
        page_per_sub = max(1, (section.page_end - section.page_start + 1) // len(subsections_data))
        
        for i, sub in enumerate(subsections_data):
            subsections.append(SectionOutline(
                id=f"{section.id}_{i+1}",
                title=sub.get("title", f"Alt BÃ¶lÃ¼m {i+1}"),
                level=section.level + 1,
                page_start=section.page_start + i * page_per_sub,
                page_end=section.page_start + (i + 1) * page_per_sub - 1,
                word_target=word_per_sub,
                subtopics=sub.get("subtopics", []),
                key_points=sub.get("key_points", []),
                research_queries=sub.get("research_queries", [sub.get("title", "")]),
                parent_id=section.id
            ))
        
        return subsections


class ResearcherAgent(BaseAgent):
    """
    AraÅŸtÄ±rmacÄ± Ajan
    
    GÃ¶revler:
    - Web aramasÄ±
    - Akademik kaynak aramasÄ±
    - RAG ile yerel kaynak aramasÄ±
    - Claim extraction (Ä°ddia Ã§Ä±karma)
    - Conflict detection (Ã‡eliÅŸki tespiti)
    """
    
    def __init__(self, global_state: GlobalState):
        super().__init__(AgentRole.RESEARCHER, global_state)
        self.academic_engine = AcademicSearchEngine()
        self.web_engine = WebSearchEngine()
    
    async def research_section(
        self,
        section: SectionOutline,
        config: DeepScholarConfig,
        local_state: LocalState
    ) -> List[ResearchItem]:
        """BÃ¶lÃ¼m iÃ§in araÅŸtÄ±rma yap."""
        all_results = []
        
        # AraÅŸtÄ±rma sorgularÄ±
        queries = section.research_queries or [section.title]
        queries.extend(section.key_points[:3])
        queries = list(set(queries))[:8]  # Max 8 sorgu
        
        tasks = []
        
        # Web aramasÄ±
        if config.web_search in ["on", "auto"]:
            for query in queries[:3]:
                tasks.append(self.web_engine.search(query, 3))
        
        # Akademik arama
        if config.academic_search:
            for query in queries[:3]:
                tasks.append(self.academic_engine.search_all(query, 3))
        
        # Paralel arama
        if config.parallel_research:
            results_lists = await asyncio.gather(*tasks, return_exceptions=True)
            for results in results_lists:
                if isinstance(results, list):
                    all_results.extend(results)
        else:
            for task in tasks:
                try:
                    results = await task
                    all_results.extend(results)
                except:
                    pass
        
        # RAG aramasÄ±
        try:
            from core.vector_store import vector_store
            for query in queries[:5]:
                rag_results = vector_store.search_with_scores(
                    query=query,
                    n_results=5,
                    score_threshold=0.3
                )
                for r in rag_results:
                    all_results.append(ResearchItem(
                        id=f"rag_{hashlib.md5(r.get('document', '')[:100].encode()).hexdigest()[:8]}",
                        content=r.get("document", ""),
                        source_title=r.get("metadata", {}).get("original_filename", "Local Document"),
                        source_type="local",
                        relevance_score=r.get("score", 0.5),
                        reliability_score=0.8
                    ))
        except Exception as e:
            print(f"[RAG Search Error] {e}")
        
        # Deduplicate ve sÄ±rala
        seen = set()
        unique_results = []
        for r in sorted(all_results, key=lambda x: x.relevance_score * x.reliability_score, reverse=True):
            content_hash = hashlib.md5(r.content[:200].encode()).hexdigest()
            if content_hash not in seen:
                seen.add(content_hash)
                unique_results.append(r)
        
        return unique_results[:config.max_sources_per_section]
    
    async def extract_claims(
        self, 
        research_items: List[ResearchItem]
    ) -> List[Dict]:
        """
        Kaynaklardan iddialar ve kanÄ±tlar Ã§Ä±kar.
        Cross-Pollination iÃ§in temel.
        """
        if not research_items:
            return []
        
        sources_text = "\n\n".join([
            f"[KAYNAK {i+1}] ({r.source_title}):\n{r.content[:500]}"
            for i, r in enumerate(research_items[:8])
        ])
        
        prompt = f"""Bu kaynaklardan ana iddialarÄ± (claims) ve kanÄ±tlarÄ± (evidence) Ã§Ä±kar:

{sources_text}

Her iddia iÃ§in:
1. Ä°ddia metni
2. Hangi kaynaktan geldiÄŸi
3. Destekleyen kanÄ±t
4. GÃ¼ven skoru (0-1)

JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
[
  {{
    "claim": "Ä°ddia metni",
    "source_index": 1,
    "evidence": "Destekleyen kanÄ±t",
    "confidence": 0.85
  }}
]
```"""

        response = await self._llm_generate(prompt)
        claims = self._parse_json(response)
        
        return claims if claims else []
    
    async def detect_conflicts(
        self, 
        claims: List[Dict]
    ) -> List[Dict]:
        """
        Ã‡eliÅŸen iddialarÄ± tespit et.
        Cross-Pollination sentez iÃ§in kritik.
        """
        if len(claims) < 2:
            return []
        
        claims_text = "\n".join([
            f"{i+1}. {c.get('claim', '')} (Kaynak {c.get('source_index', '?')})"
            for i, c in enumerate(claims)
        ])
        
        prompt = f"""Bu iddialarÄ± analiz et ve Ã§eliÅŸenleri bul:

{claims_text}

Ã‡eliÅŸen iddia Ã§iftlerini bul ve aÃ§Ä±kla. JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
[
  {{
    "claim_1_index": 1,
    "claim_2_index": 3,
    "conflict_type": "factual|methodological|interpretive",
    "description": "Ã‡eliÅŸkinin aÃ§Ä±klamasÄ±",
    "possible_resolution": "Muhtemel aÃ§Ä±klama"
  }}
]
```

EÄŸer Ã§eliÅŸki yoksa boÅŸ liste dÃ¶ndÃ¼r: []"""

        response = await self._llm_generate(prompt)
        conflicts = self._parse_json(response)
        
        return conflicts if conflicts else []


# ============================================================================
# VISUAL GENERATOR - PREMIUM FEATURE
# ============================================================================

class VisualGenerator:
    """
    GÃ¶rsel Ãœretici - Premium Ã–zellik
    
    DÃ¶kÃ¼man iÃ§ine eklenebilecek gÃ¶rsel Ã¶ÄŸeler:
    - Mermaid diyagramlarÄ± (flowchart, sequence, mindmap, timeline, pie, gantt)
    - ASCII tablolar ve grafikler
    - LaTeX formÃ¼ller
    - KarÅŸÄ±laÅŸtÄ±rma tablolarÄ±
    - Ä°statistik kutularÄ±
    - Kod bloklarÄ±
    """
    
    def __init__(self):
        self.supported_types = list(VisualType)
    
    async def _llm_generate(self, prompt: str, temperature: float = 0.7) -> str:
        """LLM ile iÃ§erik Ã¼ret."""
        try:
            result = await llm_manager.generate_with_model(
                prompt=prompt,
                temperature=temperature,
                max_tokens=2000
            )
            return result.get("response", "")
        except Exception as e:
            return ""
    
    async def generate_visuals_for_section(
        self,
        section_title: str,
        section_content: str,
        topic: str,
        config: DeepScholarConfig
    ) -> List[Dict[str, Any]]:
        """BÃ¶lÃ¼m iÃ§in uygun gÃ¶rseller Ã¼ret."""
        visuals = []
        
        if not config.enable_visuals:
            return visuals
        
        # Hangi gÃ¶rsel tiplerinin uygun olduÄŸunu belirle
        suitable_types = await self._analyze_content_for_visuals(
            section_title, section_content, topic, config
        )
        
        for visual_type in suitable_types[:config.visuals_per_section]:
            visual = await self._generate_visual(
                visual_type, section_title, section_content, topic, config
            )
            if visual:
                visuals.append(visual)
        
        return visuals
    
    async def _analyze_content_for_visuals(
        self,
        section_title: str,
        section_content: str,
        topic: str,
        config: DeepScholarConfig
    ) -> List[VisualType]:
        """Ä°Ã§eriÄŸe uygun gÃ¶rsel tiplerini belirle."""
        content_preview = section_content[:1500]
        
        prompt = f"""Bu bÃ¶lÃ¼m iÃ§eriÄŸini analiz et ve en uygun gÃ¶rsel tiplerini seÃ§.

BÃ–LÃœM: {section_title}
KONU: {topic}
Ä°Ã‡ERÄ°K:
{content_preview}

Mevcut gÃ¶rsel tipleri:
1. mermaid_flowchart - SÃ¼reÃ§, akÄ±ÅŸ, karar aÄŸacÄ± iÃ§in
2. mermaid_mindmap - Kavram haritasÄ±, iliÅŸkiler iÃ§in
3. mermaid_timeline - Tarihsel olaylar, kronoloji iÃ§in
4. mermaid_pie - DaÄŸÄ±lÄ±m, oran gÃ¶sterimi iÃ§in
5. ascii_table - KarÅŸÄ±laÅŸtÄ±rma, veri tablosu iÃ§in
6. latex_formula - Matematiksel formÃ¼ller iÃ§in
7. comparison_table - A vs B karÅŸÄ±laÅŸtÄ±rmasÄ± iÃ§in
8. statistics_box - Ä°statistik, sayÄ±sal veri vurgusu iÃ§in
9. code_block - Kod Ã¶rneÄŸi iÃ§in

Ä°Ã§eriÄŸe EN UYGUN 2-3 gÃ¶rsel tipini JSON array olarak dÃ¶ndÃ¼r.
Ã–rnek: ["mermaid_flowchart", "statistics_box"]

Sadece konuyla ilgili ve faydalÄ± olacak gÃ¶rselleri seÃ§."""

        response = await self._llm_generate(prompt, temperature=0.3)
        
        try:
            # JSON parse
            import re
            json_match = re.search(r'\[.*?\]', response, re.DOTALL)
            if json_match:
                types_list = json.loads(json_match.group())
                return [VisualType(t) for t in types_list if t in [v.value for v in VisualType]]
        except:
            pass
        
        # VarsayÄ±lan: flowchart ve statistics_box
        return [VisualType.MERMAID_FLOWCHART, VisualType.STATISTICS_BOX]
    
    async def _generate_visual(
        self,
        visual_type: VisualType,
        section_title: str,
        section_content: str,
        topic: str,
        config: DeepScholarConfig
    ) -> Optional[Dict[str, Any]]:
        """Belirli tipte gÃ¶rsel Ã¼ret."""
        
        generators = {
            VisualType.MERMAID_FLOWCHART: self._generate_mermaid_flowchart,
            VisualType.MERMAID_MINDMAP: self._generate_mermaid_mindmap,
            VisualType.MERMAID_TIMELINE: self._generate_mermaid_timeline,
            VisualType.MERMAID_PIE: self._generate_mermaid_pie,
            VisualType.MERMAID_SEQUENCE: self._generate_mermaid_sequence,
            VisualType.ASCII_TABLE: self._generate_ascii_table,
            VisualType.COMPARISON_TABLE: self._generate_comparison_table,
            VisualType.STATISTICS_BOX: self._generate_statistics_box,
            VisualType.LATEX_FORMULA: self._generate_latex_formula,
            VisualType.CODE_BLOCK: self._generate_code_block,
        }
        
        generator = generators.get(visual_type)
        if generator:
            return await generator(section_title, section_content, topic, config)
        
        return None
    
    async def _generate_mermaid_flowchart(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Mermaid flowchart Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Mermaid flowchart diyagramÄ± oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K Ã–ZETÄ°: {content[:800]}

Mermaid flowchart formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
```mermaid
flowchart TD
    A[BaÅŸlangÄ±Ã§] --> B{{Karar}}
    B -->|Evet| C[SonuÃ§ 1]
    B -->|HayÄ±r| D[SonuÃ§ 2]
```

Sadece Mermaid kodu dÃ¶ndÃ¼r, aÃ§Ä±klama ekleme. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        
        # Mermaid kodunu temizle
        code = self._clean_mermaid_code(code)
        
        return {
            "type": VisualType.MERMAID_FLOWCHART.value,
            "title": f"ğŸ“Š {section_title} - AkÄ±ÅŸ ÅemasÄ±",
            "code": code,
            "render_type": "mermaid"
        }
    
    async def _generate_mermaid_mindmap(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Mermaid mindmap Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Mermaid mindmap diyagramÄ± oluÅŸtur.

BÃ–LÃœM: {section_title}
KONU: {topic}
Ä°Ã‡ERÄ°K: {content[:800]}

Mermaid mindmap formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
```mermaid
mindmap
  root((Ana Konu))
    Alt Konu 1
      Detay A
      Detay B
    Alt Konu 2
      Detay C
```

Sadece Mermaid kodu dÃ¶ndÃ¼r. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        code = self._clean_mermaid_code(code)
        
        return {
            "type": VisualType.MERMAID_MINDMAP.value,
            "title": f"ğŸ§  {section_title} - Kavram HaritasÄ±",
            "code": code,
            "render_type": "mermaid"
        }
    
    async def _generate_mermaid_timeline(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Mermaid timeline Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Mermaid timeline diyagramÄ± oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

Mermaid timeline formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
```mermaid
timeline
    title Tarihsel GeliÅŸim
    1990 : Olay 1
    2000 : Olay 2
    2010 : Olay 3
```

Sadece Mermaid kodu dÃ¶ndÃ¼r. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        code = self._clean_mermaid_code(code)
        
        return {
            "type": VisualType.MERMAID_TIMELINE.value,
            "title": f"ğŸ“… {section_title} - Zaman Ã‡izelgesi",
            "code": code,
            "render_type": "mermaid"
        }
    
    async def _generate_mermaid_pie(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Mermaid pie chart Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Mermaid pasta grafiÄŸi oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

Ä°Ã§erikten uygun bir daÄŸÄ±lÄ±m Ã§Ä±kar ve Mermaid pie formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
```mermaid
pie showData
    title DaÄŸÄ±lÄ±m
    "Kategori A" : 40
    "Kategori B" : 35
    "Kategori C" : 25
```

Sadece Mermaid kodu dÃ¶ndÃ¼r. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        code = self._clean_mermaid_code(code)
        
        return {
            "type": VisualType.MERMAID_PIE.value,
            "title": f"ğŸ¥§ {section_title} - DaÄŸÄ±lÄ±m",
            "code": code,
            "render_type": "mermaid"
        }
    
    async def _generate_mermaid_sequence(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Mermaid sequence diagram Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Mermaid sequence diyagramÄ± oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

Mermaid sequence formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
```mermaid
sequenceDiagram
    participant A as KullanÄ±cÄ±
    participant B as Sistem
    A->>B: Ä°stek
    B-->>A: YanÄ±t
```

Sadece Mermaid kodu dÃ¶ndÃ¼r. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        code = self._clean_mermaid_code(code)
        
        return {
            "type": VisualType.MERMAID_SEQUENCE.value,
            "title": f"ğŸ”„ {section_title} - SÄ±ralÄ± Diyagram",
            "code": code,
            "render_type": "mermaid"
        }
    
    async def _generate_ascii_table(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """ASCII tablo Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir Markdown tablosu oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

Ä°Ã§erikten anlamlÄ± veriler Ã§Ä±kar ve Markdown tablo formatÄ±nda dÃ¶ndÃ¼r. Ã–rnek:
| Ã–zellik | DeÄŸer | AÃ§Ä±klama |
|---------|-------|----------|
| A | 100 | Detay A |
| B | 200 | Detay B |

Sadece tablo kodunu dÃ¶ndÃ¼r. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        
        return {
            "type": VisualType.ASCII_TABLE.value,
            "title": f"ğŸ“‹ {section_title} - Veri Tablosu",
            "code": code.strip(),
            "render_type": "markdown"
        }
    
    async def _generate_comparison_table(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """KarÅŸÄ±laÅŸtÄ±rma tablosu Ã¼ret."""
        prompt = f"""Bu iÃ§erik iÃ§in bir karÅŸÄ±laÅŸtÄ±rma tablosu oluÅŸtur.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

Ä°ki veya daha fazla kavramÄ±/yaklaÅŸÄ±mÄ± karÅŸÄ±laÅŸtÄ±r. Markdown tablo formatÄ±nda dÃ¶ndÃ¼r:
| Ã–zellik | Kavram A | Kavram B |
|---------|----------|----------|
| Avantaj | âœ… X | âŒ Y |
| Dezavantaj | âš ï¸ Z | âœ… W |

Sadece tablo kodunu dÃ¶ndÃ¼r. Emoji kullan. TÃ¼rkÃ§e metin kullan."""

        code = await self._llm_generate(prompt, temperature=0.5)
        
        return {
            "type": VisualType.COMPARISON_TABLE.value,
            "title": f"âš–ï¸ {section_title} - KarÅŸÄ±laÅŸtÄ±rma",
            "code": code.strip(),
            "render_type": "markdown"
        }
    
    async def _generate_statistics_box(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Ä°statistik kutusu Ã¼ret."""
        prompt = f"""Bu iÃ§erikten Ã¶nemli istatistikleri ve sayÄ±sal verileri Ã§Ä±kar.

BÃ–LÃœM: {section_title}
Ä°Ã‡ERÄ°K: {content[:800]}

JSON formatÄ±nda dÃ¶ndÃ¼r:
{{
  "stats": [
    {{"label": "Toplam KullanÄ±cÄ±", "value": "1.5M", "icon": "ğŸ‘¥", "trend": "up"}},
    {{"label": "BÃ¼yÃ¼me OranÄ±", "value": "%25", "icon": "ğŸ“ˆ", "trend": "up"}},
    {{"label": "Pazar PayÄ±", "value": "%40", "icon": "ğŸ¯", "trend": "stable"}}
  ],
  "highlight": "Ana bulgu veya Ã¶nemli sonuÃ§"
}}

Ä°Ã§erikten gerÃ§ekÃ§i ve tutarlÄ± veriler Ã§Ä±kar. Veri yoksa makul tahminler yap."""

        response = await self._llm_generate(prompt, temperature=0.5)
        
        try:
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
            else:
                data = {"stats": [], "highlight": ""}
        except:
            data = {"stats": [], "highlight": ""}
        
        return {
            "type": VisualType.STATISTICS_BOX.value,
            "title": f"ğŸ“Š {section_title} - Ä°statistikler",
            "data": data,
            "render_type": "statistics"
        }
    
    async def _generate_latex_formula(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """LaTeX formÃ¼l Ã¼ret."""
        if not config.enable_formulas:
            return None
        
        prompt = f"""Bu iÃ§erik iÃ§in uygun matematiksel formÃ¼ller Ã¼ret.

BÃ–LÃœM: {section_title}
KONU: {topic}
Ä°Ã‡ERÄ°K: {content[:600]}

LaTeX formatÄ±nda formÃ¼ller dÃ¶ndÃ¼r. Ã–rnek:
$$E = mc^2$$
$$\\sum_{{i=1}}^{{n}} x_i = x_1 + x_2 + ... + x_n$$

Ä°Ã§erikle ilgili 1-3 formÃ¼l Ã¼ret. Sadece LaTeX kodunu dÃ¶ndÃ¼r."""

        code = await self._llm_generate(prompt, temperature=0.5)
        
        return {
            "type": VisualType.LATEX_FORMULA.value,
            "title": f"ğŸ”¢ {section_title} - FormÃ¼ller",
            "code": code.strip(),
            "render_type": "latex"
        }
    
    async def _generate_code_block(
        self, section_title: str, content: str, topic: str, config: DeepScholarConfig
    ) -> Dict[str, Any]:
        """Kod bloÄŸu Ã¼ret."""
        if not config.enable_code_examples:
            return None
        
        prompt = f"""Bu iÃ§erik iÃ§in Ã¶rnek bir kod bloÄŸu oluÅŸtur.

BÃ–LÃœM: {section_title}
KONU: {topic}
Ä°Ã‡ERÄ°K: {content[:600]}

Konuyla ilgili pratik ve eÄŸitici bir kod Ã¶rneÄŸi yaz.
Python, JavaScript veya uygun baÅŸka bir dilde olabilir.

Markdown code block formatÄ±nda dÃ¶ndÃ¼r:
```python
# Kod Ã¶rneÄŸi
```"""

        code = await self._llm_generate(prompt, temperature=0.5)
        
        return {
            "type": VisualType.CODE_BLOCK.value,
            "title": f"ğŸ’» {section_title} - Kod Ã–rneÄŸi",
            "code": code.strip(),
            "render_type": "code"
        }
    
    def _clean_mermaid_code(self, code: str) -> str:
        """Mermaid kodunu temizle."""
        # Markdown code block'larÄ±nÄ± kaldÄ±r
        code = re.sub(r'```mermaid\s*', '', code)
        code = re.sub(r'```\s*$', '', code)
        code = re.sub(r'```', '', code)
        return code.strip()


class WriterAgent(BaseAgent):
    """
    Yazar Ajan
    
    GÃ¶revler:
    - BÃ¶lÃ¼m iÃ§eriÄŸi yazma
    - Kaynak entegrasyonu
    - Stil tutarlÄ±lÄ±ÄŸÄ±
    - GeÃ§iÅŸ paragraflarÄ±
    """
    
    def __init__(self, global_state: GlobalState):
        super().__init__(AgentRole.WRITER, global_state)
    
    async def write_section(
        self,
        section: SectionOutline,
        research: List[ResearchItem],
        local_state: LocalState,
        config: DeepScholarConfig
    ) -> Tuple[str, List[Citation]]:
        """BÃ¶lÃ¼m iÃ§eriÄŸi yaz."""
        
        lang_prompts = {
            DocumentLanguage.TURKISH: "TÃ¼rkÃ§e",
            DocumentLanguage.ENGLISH: "English",
            DocumentLanguage.GERMAN: "Deutsch"
        }
        
        style_prompts = {
            "academic": "akademik, formal ve detaylÄ±",
            "casual": "samimi, anlaÅŸÄ±lÄ±r ve akÄ±cÄ±",
            "detailed": "kapsamlÄ±, her detayÄ± aÃ§Ä±klayan",
            "summary": "Ã¶zet, ana noktalarÄ± vurgulayan",
            "exam_prep": "sÄ±nava yÃ¶nelik, Ã¶nemli noktalarÄ± vurgulayan"
        }
        
        # Kaynak metni oluÅŸtur
        sources_text = ""
        source_map = {}
        for i, r in enumerate(research[:10], 1):
            sources_text += f"\n[KAYNAK {i}] ({r.source_title}"
            if r.year:
                sources_text += f", {r.year}"
            sources_text += f"):\n{r.content[:600]}\n"
            source_map[i] = r
        
        # Ã–nceki bÃ¶lÃ¼m Ã¶zeti
        prev_summary = ""
        if local_state.previous_section_summary:
            prev_summary = f"\nÃ–NCEKÄ° BÃ–LÃœM Ã–ZETÄ°:\n{local_state.previous_section_summary}\n"
        
        # Tez statement
        thesis = ""
        if self.global_state.thesis_statement:
            thesis = f"\nANA TEZ: {self.global_state.thesis_statement}\n"
        
        # Terimler sÃ¶zlÃ¼ÄŸÃ¼
        glossary = ""
        if self.global_state.global_glossary:
            glossary = "\nKULLANILACAK TERÄ°MLER:\n" + "\n".join([
                f"- {term}: {defn}" 
                for term, defn in list(self.global_state.global_glossary.items())[:10]
            ]) + "\n"
        
        prompt = f"""Bu bÃ¶lÃ¼m iÃ§in akademik iÃ§erik yaz.

DÃ–KÃœMAN: {self.global_state.document_title}
BÃ–LÃœM: {section.title}
BÃ–LÃœM SEVÄ°YESÄ°: {'#' * section.level} (Markdown baÅŸlÄ±k)
ALT KONULAR: {', '.join(section.subtopics)}
ANAHTAR NOKTALAR: {', '.join(section.key_points)}

DÄ°L: {lang_prompts.get(config.language, 'TÃ¼rkÃ§e')}
YAZI STÄ°LÄ°: {style_prompts.get(config.style, 'akademik')}
KELÄ°ME HEDEFÄ°: ~{section.word_target} kelime
{thesis}
{prev_summary}
{glossary}

KAYNAKLAR:
{sources_text}

YAZIM KURALLARI:
1. {'#' * section.level} ile baÅŸlÄ±k kullan
2. Kaynaklara metin iÃ§inde [KAYNAK X] ÅŸeklinde atÄ±f yap
3. Akademik ve tutarlÄ± bir dil kullan
4. Paragraflar arasÄ± geÃ§iÅŸler yumuÅŸak olsun
5. Ã–nemli kavramlarÄ± **kalÄ±n** yap
6. Gerekirse madde iÅŸaretleri kullan
7. Kelime hedefine yaklaÅŸ

{f'Ã–ZEL TALÄ°MATLAR: {config.custom_instructions}' if config.custom_instructions else ''}

Åimdi bu bÃ¶lÃ¼mÃ¼n iÃ§eriÄŸini yaz:"""

        content = await self._llm_generate(prompt)
        
        # Citation'larÄ± Ã§Ä±kar
        citations = []
        citation_pattern = r'\[KAYNAK (\d+)\]'
        
        for match in re.finditer(citation_pattern, content):
            src_idx = int(match.group(1))
            if src_idx in source_map:
                r = source_map[src_idx]
                
                # Citation oluÅŸtur
                citation = Citation(
                    id=f"cite_{self.global_state.citation_counter + 1}",
                    source_type=r.source_type,
                    title=r.source_title,
                    authors=r.authors,
                    year=r.year,
                    url=r.source_url,
                    used_in_sections=[section.id]
                )
                
                citations.append(citation)
                self.global_state.citation_counter += 1
                
                # Global state'e ekle
                if citation.id not in self.global_state.all_citations:
                    self.global_state.all_citations[citation.id] = citation
        
        # [KAYNAK X] -> [X] formatÄ±na Ã§evir
        clean_content = content
        for i in range(1, 20):
            clean_content = clean_content.replace(f"[KAYNAK {i}]", f"[{i}]")
        
        return clean_content, citations


class FactCheckerAgent(BaseAgent):
    """
    GerÃ§ek KontrolÃ¼ AjanÄ±
    
    GÃ¶revler:
    - HalÃ¼sinasyon tespiti
    - Referans doÄŸrulama
    - SayÄ±sal doÄŸruluk kontrolÃ¼
    """
    
    def __init__(self, global_state: GlobalState):
        super().__init__(AgentRole.FACT_CHECKER, global_state)
    
    async def verify_content(
        self,
        content: str,
        research: List[ResearchItem]
    ) -> Dict:
        """Ä°Ã§eriÄŸi doÄŸrula."""
        
        sources_text = "\n".join([
            f"[KAYNAK {i+1}]: {r.content[:300]}"
            for i, r in enumerate(research[:8])
        ])
        
        prompt = f"""Bu iÃ§eriÄŸi kaynaklarla karÅŸÄ±laÅŸtÄ±r ve doÄŸrula:

Ä°Ã‡ERÄ°K:
{content[:2000]}

KAYNAKLAR:
{sources_text}

Her faktÃ¼el iddia iÃ§in:
1. Ä°ddiayÄ± bul
2. Kaynakta doÄŸrulama var mÄ±?
3. GÃ¼ven skoru (0-1)

JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
{{
  "verified_claims": [
    {{"claim": "...", "verified": true, "source_index": 1, "confidence": 0.9}}
  ],
  "unverified_claims": [
    {{"claim": "...", "issue": "Kaynaklarda bulunamadÄ±"}}
  ],
  "overall_score": 0.85,
  "recommendations": ["..."]
}}
```"""

        response = await self._llm_generate(prompt)
        result = self._parse_json(response)
        
        return result if result else {
            "verified_claims": [],
            "unverified_claims": [],
            "overall_score": 0.7,
            "recommendations": []
        }


class UserProxyAgent(BaseAgent):
    """
    KullanÄ±cÄ± SimÃ¼lasyonu AjanÄ±
    
    GÃ¶revler:
    - KullanÄ±cÄ± perspektifinden iÃ§erik deÄŸerlendirme
    - AnlaÅŸÄ±lÄ±rlÄ±k kontrolÃ¼
    - Stil uygunluÄŸu
    """
    
    def __init__(self, global_state: GlobalState, persona: str = ""):
        super().__init__(AgentRole.USER_PROXY, global_state)
        self.persona = persona
    
    async def review_content(
        self,
        content: str,
        config: DeepScholarConfig
    ) -> Dict:
        """Ä°Ã§eriÄŸi kullanÄ±cÄ± perspektifinden deÄŸerlendir."""
        
        persona_text = self.persona or config.user_persona or "genel okuyucu"
        
        prompt = f"""Sen bir okuyucu olarak bu iÃ§eriÄŸi deÄŸerlendir.

OKUYUCU PROFÄ°LÄ°: {persona_text}
DÄ°L: {config.language.value}

Ä°Ã‡ERÄ°K:
{content[:2000]}

DeÄŸerlendirme kriterleri:
1. AnlaÅŸÄ±lÄ±rlÄ±k (1-10)
2. Bilgi yoÄŸunluÄŸu (1-10)
3. AkÄ±ÅŸ ve tutarlÄ±lÄ±k (1-10)
4. Teknik terim kullanÄ±mÄ± uygun mu?
5. Eksik veya karmaÅŸÄ±k kÄ±sÄ±mlar var mÄ±?

JSON formatÄ±nda dÃ¶ndÃ¼r:
```json
{{
  "clarity_score": 8,
  "density_score": 7,
  "flow_score": 8,
  "technical_terms_ok": true,
  "issues": [
    {{"location": "2. paragraf", "issue": "Terim aÃ§Ä±klanmamÄ±ÅŸ", "suggestion": "..."}}
  ],
  "overall_feedback": "Genel deÄŸerlendirme..."
}}
```"""

        response = await self._llm_generate(prompt)
        result = self._parse_json(response)
        
        return result if result else {
            "clarity_score": 7,
            "density_score": 7,
            "flow_score": 7,
            "technical_terms_ok": True,
            "issues": [],
            "overall_feedback": "Ä°Ã§erik genel olarak iyi."
        }


class SynthesizerAgent(BaseAgent):
    """
    Sentez AjanÄ±
    
    GÃ¶revler:
    - KaynaklarÄ± sentezleme
    - Ã‡eliÅŸkileri Ã§Ã¶zme
    - BÃ¼tÃ¼nleÅŸtirici paragraflar
    """
    
    def __init__(self, global_state: GlobalState):
        super().__init__(AgentRole.SYNTHESIZER, global_state)
    
    async def synthesize_claims(
        self,
        claims: List[Dict],
        conflicts: List[Dict]
    ) -> str:
        """Ã‡eliÅŸen iddialarÄ± sentezle."""
        
        if not conflicts:
            return ""
        
        claims_text = "\n".join([
            f"{i+1}. {c.get('claim', '')} (GÃ¼ven: {c.get('confidence', 0.5)})"
            for i, c in enumerate(claims)
        ])
        
        conflicts_text = "\n".join([
            f"- Ã‡eliÅŸki: Ä°ddia {c['claim_1_index']} vs Ä°ddia {c['claim_2_index']}: {c.get('description', '')}"
            for c in conflicts
        ])
        
        prompt = f"""Bu Ã§eliÅŸkileri analiz et ve sentezle:

Ä°DDÄ°ALAR:
{claims_text}

Ã‡ELÄ°ÅKÄ°LER:
{conflicts_text}

Her Ã§eliÅŸki iÃ§in:
1. Neden farklÄ±lÄ±k var?
2. Hangi kaynak daha gÃ¼venilir?
3. Sentez cÃ¼mlesi oluÅŸtur

Akademik bir dille, Ã§eliÅŸkileri aÃ§Ä±klayan ve sentezleyen bir paragraf yaz."""

        response = await self._llm_generate(prompt)
        return response


# ============================================================================
# DEEP SCHOLAR ORCHESTRATOR
# ============================================================================

class DeepScholarOrchestrator:
    """
    DeepScholar Ana OrkestratÃ¶r
    
    TÃ¼m ajanlarÄ± koordine eder ve dÃ¶kÃ¼man Ã¼retim sÃ¼recini yÃ¶netir.
    Pause/Resume ve GÃ¶rsel Ãœretim destekler.
    """
    
    # Checkpoint'leri saklayan class-level dict
    _checkpoints: Dict[str, 'GenerationCheckpoint'] = {}
    _paused_states: Dict[str, bool] = {}
    
    def __init__(self):
        self.global_state = GlobalState()
        self.local_state = LocalState()
        
        # Ajanlar
        self.planner: Optional[PlannerAgent] = None
        self.researcher: Optional[ResearcherAgent] = None
        self.writer: Optional[WriterAgent] = None
        self.fact_checker: Optional[FactCheckerAgent] = None
        self.user_proxy: Optional[UserProxyAgent] = None
        self.synthesizer: Optional[SynthesizerAgent] = None
        
        # GÃ¶rsel Ã¼retici
        self.visual_generator = VisualGenerator()
        
        # ğŸš€ Premium V2 ModÃ¼ller
        self.dynamic_page_manager: Optional['DynamicPageManager'] = None
        self.multi_agent_debate: Optional['MultiAgentDebate'] = None
        self.realtime_streaming: Optional['RealTimeStreamingManager'] = None
        self.originality_checker: Optional['OriginalityChecker'] = None
        self.multilingual_engine: Optional['MultilingualResearchEngine'] = None
        self.analytics_engine: Optional['ResearchAnalyticsEngine'] = None
        self.literature_review: Optional['LiteratureReviewEngine'] = None
        
        # Event callback
        self._event_callback: Optional[Callable] = None
        
        # Pause/Resume state
        self._is_paused = False
        self._document_id: Optional[str] = None
    
    def set_event_callback(self, callback: Callable):
        """Event callback ayarla (WebSocket iÃ§in)."""
        self._event_callback = callback
    
    def set_document_id(self, doc_id: str):
        """DÃ¶kÃ¼man ID'sini ayarla (pause/resume iÃ§in)."""
        self._document_id = doc_id
    
    @classmethod
    def pause_generation(cls, document_id: str) -> bool:
        """Ãœretimi duraklat."""
        cls._paused_states[document_id] = True
        return True
    
    @classmethod
    def resume_generation(cls, document_id: str) -> bool:
        """Ãœretimi devam ettir."""
        cls._paused_states[document_id] = False
        return True
    
    @classmethod
    def is_paused(cls, document_id: str) -> bool:
        """DuraklatÄ±lmÄ±ÅŸ mÄ± kontrol et."""
        return cls._paused_states.get(document_id, False)
    
    @classmethod
    def get_checkpoint(cls, document_id: str) -> Optional['GenerationCheckpoint']:
        """Checkpoint'i getir."""
        return cls._checkpoints.get(document_id)
    
    @classmethod
    def save_checkpoint(cls, checkpoint: 'GenerationCheckpoint'):
        """Checkpoint'i kaydet."""
        cls._checkpoints[checkpoint.document_id] = checkpoint
    
    @classmethod
    def delete_checkpoint(cls, document_id: str):
        """Checkpoint'i sil."""
        cls._checkpoints.pop(document_id, None)
        cls._paused_states.pop(document_id, None)
    
    async def _check_pause(self) -> bool:
        """Duraklatma kontrolÃ¼."""
        if self._document_id and self.is_paused(self._document_id):
            return True
        return False
    
    async def _emit_event(
        self, 
        event_type: EventType, 
        data: Dict[str, Any]
    ):
        """Event yayÄ±nla."""
        event = {
            "type": event_type.value,
            "timestamp": datetime.now().isoformat(),
            **data
        }
        
        if self._event_callback:
            await self._event_callback(event)
    
    async def generate_document(
        self,
        config: DeepScholarConfig
    ) -> AsyncGenerator[Dict, None]:
        """
        DÃ¶kÃ¼man Ã¼retimi (ana akÄ±ÅŸ).
        
        Yields:
            Progress events
        """
        try:
            # Global state'i baÅŸlat
            self.global_state = GlobalState(
                document_title=config.title,
                document_topic=config.topic,
                target_pages=config.page_count,
                language=config.language,
                citation_style=config.citation_style
            )
            
            # ğŸš€ Premium V2 ModÃ¼llerini BaÅŸlat
            if PREMIUM_ADVANCED_AVAILABLE:
                if config.enable_dynamic_pages:
                    self.dynamic_page_manager = DynamicPageManager(
                        base_page_count=config.page_count,
                        max_expansion=config.max_page_expansion
                    )
                
                if config.enable_realtime_streaming:
                    # target_sections = outline length (will be set after planning)
                    self.realtime_streaming = RealTimeStreamingManager(
                        target_pages=config.page_count,
                        target_sections=10  # Default, will be updated after outline
                    )
                
                if config.enable_originality_check:
                    self.originality_checker = OriginalityChecker()
                
                if config.enable_analytics:
                    self.analytics_engine = ResearchAnalyticsEngine()
            
            # AjanlarÄ± oluÅŸtur
            self.planner = PlannerAgent(self.global_state)
            self.researcher = ResearcherAgent(self.global_state)
            self.writer = WriterAgent(self.global_state)
            self.fact_checker = FactCheckerAgent(self.global_state)
            self.user_proxy = UserProxyAgent(self.global_state, config.user_persona)
            self.synthesizer = SynthesizerAgent(self.global_state)
            
            # ============ PHASE 1: PLANNING ============
            yield {
                "type": EventType.PHASE_START.value,
                "phase": "planning",
                "message": "ğŸ“‹ DÃ¶kÃ¼man planlanÄ±yor...",
                "progress": 5
            }
            
            yield {
                "type": EventType.AGENT_MESSAGE.value,
                "agent": AgentRole.PLANNER.value,
                "message": f"ğŸ§  {config.page_count} sayfalÄ±k dÃ¶kÃ¼man iÃ§in master outline oluÅŸturuluyor..."
            }
            
            outline = await self.planner.create_master_outline(config)
            self.global_state.master_outline = outline
            
            yield {
                "type": EventType.PHASE_END.value,
                "phase": "planning",
                "message": f"âœ… {len(outline)} bÃ¶lÃ¼mlÃ¼k plan hazÄ±rlandÄ±",
                "progress": 10,
                "data": {
                    "outline": [
                        {"id": s.id, "title": s.title, "level": s.level, "pages": f"{s.page_start}-{s.page_end}"}
                        for s in outline
                    ]
                }
            }
            
            # ============ PHASE 2: RESEARCH ============
            yield {
                "type": EventType.PHASE_START.value,
                "phase": "research",
                "message": "ğŸ” AraÅŸtÄ±rma yapÄ±lÄ±yor...",
                "progress": 15
            }
            
            all_research: Dict[str, List[ResearchItem]] = {}
            total_sources = 0
            
            for i, section in enumerate(outline):
                yield {
                    "type": EventType.AGENT_MESSAGE.value,
                    "agent": AgentRole.RESEARCHER.value,
                    "message": f"ğŸ” BÃ¶lÃ¼m {i+1}/{len(outline)} araÅŸtÄ±rÄ±lÄ±yor: {section.title}"
                }
                
                self.local_state.current_section = section
                research = await self.researcher.research_section(section, config, self.local_state)
                all_research[section.id] = research
                total_sources += len(research)
                
                yield {
                    "type": EventType.RESEARCH_FOUND.value,
                    "section": section.title,
                    "sources_count": len(research),
                    "sources": [
                        {"title": r.source_title, "type": r.source_type, "score": r.relevance_score}
                        for r in research[:5]
                    ]
                }
                
                # Fraktal geniÅŸleme kontrolÃ¼
                if config.max_research_depth > 1 and len(research) > 5:
                    claims = await self.researcher.extract_claims(research)
                    self.local_state.extracted_claims = claims
                    
                    if config.enable_conflict_detection:
                        conflicts = await self.researcher.detect_conflicts(claims)
                        self.local_state.detected_conflicts = conflicts
                        
                        if conflicts:
                            yield {
                                "type": EventType.CONFLICT_DETECTED.value,
                                "section": section.title,
                                "conflicts": conflicts
                            }
            
            yield {
                "type": EventType.PHASE_END.value,
                "phase": "research",
                "message": f"ğŸ“š Toplam {total_sources} kaynak bulundu",
                "progress": 30
            }
            
            # ğŸš€ Research Analytics (Premium V2)
            if PREMIUM_ADVANCED_AVAILABLE and config.enable_analytics and self.analytics_engine:
                yield {
                    "type": EventType.AGENT_THINKING.value,
                    "agent": "ResearchAnalytics",
                    "thought": "ğŸ“Š AraÅŸtÄ±rma kalitesi analiz ediliyor..."
                }
                
                # TÃ¼m kaynaklarÄ± dÃ¼z listeye Ã§evir
                flat_sources = []
                for section_id, research_items in all_research.items():
                    for item in research_items:
                        flat_sources.append({
                            "id": item.id,
                            "title": item.source_title,
                            "type": item.source_type,
                            "content": item.content[:500] if item.content else "",
                            "keywords": [],
                            "year": 2024
                        })
                
                analytics_report = await self.analytics_engine.analyze_sources(
                    flat_sources, config.topic
                )
                
                yield {
                    "type": "research_analytics",
                    "quality_score": analytics_report.quality_score,
                    "diversity_score": round(analytics_report.source_metrics.diversity_score, 2),
                    "recency_score": round(analytics_report.source_metrics.recency_score, 2),
                    "topic_clusters": [c.name for c in analytics_report.topic_clusters[:5]],
                    "gaps": analytics_report.gaps_identified[:3],
                    "recommendations": analytics_report.recommendations[:3],
                    "message": f"ğŸ“Š AraÅŸtÄ±rma kalitesi: {analytics_report.quality_score}/100"
                }
            
            # ============ PHASE 3: WRITING ============
            yield {
                "type": EventType.PHASE_START.value,
                "phase": "writing",
                "message": "âœï¸ Ä°Ã§erik yazÄ±lÄ±yor...",
                "progress": 35
            }
            
            all_content = []
            all_citations = []
            
            for i, section in enumerate(outline):
                progress = 35 + int((i / len(outline)) * 45)
                
                yield {
                    "type": EventType.SECTION_START.value,
                    "section_index": i,
                    "section_title": section.title,
                    "progress": progress
                }
                
                yield {
                    "type": EventType.AGENT_MESSAGE.value,
                    "agent": AgentRole.WRITER.value,
                    "message": f"âœï¸ YazÄ±lÄ±yor: {section.title} ({section.word_target} kelime hedef)"
                }
                
                # Pause kontrolÃ¼
                if await self._check_pause():
                    # Checkpoint kaydet
                    checkpoint = GenerationCheckpoint(
                        document_id=self._document_id or "",
                        config={
                            "title": config.title,
                            "topic": config.topic,
                            "page_count": config.page_count,
                            "language": config.language.value,
                            "citation_style": config.citation_style.value,
                            "style": config.style
                        },
                        progress=progress,
                        current_phase="writing",
                        completed_sections=[
                            {"id": c["section_id"], "title": c["title"], "content": c["content"]}
                            for c in all_content
                        ],
                        pending_sections=[
                            {"id": s.id, "title": s.title}
                            for s in outline[i:]
                        ],
                        all_research={
                            k: [{"id": r.id, "content": r.content, "source_title": r.source_title}
                                for r in v]
                            for k, v in all_research.items()
                        },
                        global_state={
                            "completed_sections": dict(self.global_state.completed_sections),
                            "section_summaries": dict(self.global_state.section_summaries)
                        }
                    )
                    self.save_checkpoint(checkpoint)
                    
                    yield {
                        "type": EventType.PAUSED.value,
                        "message": "â¸ï¸ Ãœretim duraklatÄ±ldÄ±. KaldÄ±ÄŸÄ±nÄ±z yerden devam edebilirsiniz.",
                        "progress": progress,
                        "checkpoint_id": self._document_id,
                        "completed_sections": len(all_content),
                        "pending_sections": len(outline) - i
                    }
                    
                    # Pause dÃ¶ngÃ¼sÃ¼ - resume bekle
                    while await self._check_pause():
                        await asyncio.sleep(1)
                    
                    yield {
                        "type": EventType.RESUMED.value,
                        "message": "â–¶ï¸ Ãœretim devam ediyor...",
                        "progress": progress
                    }
                
                # Local state gÃ¼ncelle
                self.local_state.current_section = section
                self.local_state.current_sources = all_research.get(section.id, [])
                
                if i > 0:
                    prev_section = outline[i-1]
                    self.local_state.previous_section_summary = self.global_state.section_summaries.get(
                        prev_section.id, ""
                    )
                
                # YazÄ±m
                content, citations = await self.writer.write_section(
                    section, 
                    self.local_state.current_sources,
                    self.local_state,
                    config
                )
                
                # GÃ¶rsel Ã¼retimi (Premium)
                visuals = []
                if config.enable_visuals:
                    yield {
                        "type": EventType.AGENT_MESSAGE.value,
                        "agent": AgentRole.SYNTHESIZER.value,
                        "message": f"ğŸ¨ GÃ¶rseller Ã¼retiliyor: {section.title}"
                    }
                    
                    visuals = await self.visual_generator.generate_visuals_for_section(
                        section.title,
                        content,
                        config.topic,
                        config
                    )
                    
                    for visual in visuals:
                        yield {
                            "type": EventType.VISUAL_GENERATED.value,
                            "section": section.title,
                            "visual_type": visual.get("type"),
                            "visual_title": visual.get("title"),
                            "visual": visual
                        }
                    
                    # GÃ¶rselleri iÃ§eriÄŸe ekle
                    if visuals:
                        content = self._integrate_visuals(content, visuals)
                
                all_content.append({
                    "section_id": section.id,
                    "title": section.title,
                    "level": section.level,
                    "content": content,
                    "word_count": len(content.split()),
                    "visuals": visuals
                })
                all_citations.extend(citations)
                
                # Global state gÃ¼ncelle
                self.global_state.completed_sections[section.id] = content
                
                # Ã–zet oluÅŸtur (sonraki bÃ¶lÃ¼m iÃ§in)
                summary_prompt = f"Bu iÃ§eriÄŸi 2-3 cÃ¼mleyle Ã¶zetle:\n{content[:1000]}"
                summary = await self.writer._llm_generate(summary_prompt, temperature=0.3)
                self.global_state.section_summaries[section.id] = summary[:300]
                
                # Fact check (opsiyonel)
                if config.enable_fact_checking:
                    yield {
                        "type": EventType.AGENT_MESSAGE.value,
                        "agent": AgentRole.FACT_CHECKER.value,
                        "message": f"ğŸ” DoÄŸrulama: {section.title}"
                    }
                    
                    verification = await self.fact_checker.verify_content(
                        content, 
                        self.local_state.current_sources
                    )
                    
                    yield {
                        "type": EventType.FACT_CHECK.value,
                        "section": section.title,
                        "score": verification.get("overall_score", 0.7),
                        "verified_count": len(verification.get("verified_claims", [])),
                        "unverified_count": len(verification.get("unverified_claims", []))
                    }
                
                # User proxy review (opsiyonel)
                if config.enable_user_proxy:
                    yield {
                        "type": EventType.AGENT_MESSAGE.value,
                        "agent": AgentRole.USER_PROXY.value,
                        "message": f"ğŸ‘¤ Okuyucu deÄŸerlendirmesi: {section.title}"
                    }
                    
                    review = await self.user_proxy.review_content(content, config)
                    
                    yield {
                        "type": EventType.USER_PROXY_FEEDBACK.value,
                        "section": section.title,
                        "clarity": review.get("clarity_score", 7),
                        "issues": review.get("issues", [])
                    }
                
                # ğŸš€ Originality Check (Premium V2)
                if PREMIUM_ADVANCED_AVAILABLE and config.enable_originality_check and self.originality_checker:
                    yield {
                        "type": EventType.AGENT_THINKING.value,
                        "agent": "OriginalityChecker",
                        "thought": f"ğŸ“ Orijinallik kontrolÃ¼ yapÄ±lÄ±yor: {section.title}"
                    }
                    
                    # Kaynak metinleri al
                    source_texts = [
                        r.content for r in self.local_state.current_sources
                        if r.content
                    ]
                    
                    originality_report = await self.originality_checker.check_originality(
                        content, source_texts
                    )
                    
                    yield {
                        "type": "originality_check",
                        "section": section.title,
                        "originality_score": originality_report.originality_score,
                        "similarity_index": originality_report.similarity_index,
                        "unique_phrases_ratio": originality_report.unique_phrases_ratio,
                        "citation_count": len(originality_report.cited_passages),
                        "message": f"ğŸ“Š Orijinallik: {originality_report.originality_score:.0%}"
                    }
                
                yield {
                    "type": EventType.SECTION_COMPLETE.value,
                    "section_index": i,
                    "section_title": section.title,
                    "section_level": section.level,
                    "visuals": visuals,
                    "word_count": len(content.split()),
                    "content": content,  # Full content for live preview
                    "content_preview": content[:500] + "..." if len(content) > 500 else content,
                    "progress": progress + 5
                }
                
                # Local state temizle
                self.local_state.clear()
            
            yield {
                "type": EventType.PHASE_END.value,
                "phase": "writing",
                "message": "âœ… Ä°Ã§erik yazÄ±mÄ± tamamlandÄ±",
                "progress": 85
            }
            
            # ============ PHASE 4: BIBLIOGRAPHY ============
            yield {
                "type": EventType.PHASE_START.value,
                "phase": "bibliography",
                "message": "ğŸ“– KaynakÃ§a oluÅŸturuluyor...",
                "progress": 88
            }
            
            bibliography = self._create_bibliography(config)
            
            yield {
                "type": EventType.PHASE_END.value,
                "phase": "bibliography",
                "message": f"ğŸ“š {len(self.global_state.all_citations)} kaynak listelendi",
                "progress": 92
            }
            
            # ============ PHASE 5: FINALIZE ============
            yield {
                "type": EventType.PHASE_START.value,
                "phase": "finalize",
                "message": "ğŸ”§ DÃ¶kÃ¼man birleÅŸtiriliyor...",
                "progress": 94
            }
            
            # Final dÃ¶kÃ¼man
            final_content = self._combine_content(all_content, bibliography, config)
            
            yield {
                "type": EventType.COMPLETE.value,
                "message": "ğŸ‰ DÃ¶kÃ¼man baÅŸarÄ±yla oluÅŸturuldu!",
                "progress": 100,
                "document": {
                    "title": config.title,
                    "content": final_content,
                    "word_count": len(final_content.split()),
                    "page_count": config.page_count,
                    "citations_count": len(self.global_state.all_citations),
                    "sections": [
                        {"id": s.id, "title": s.title}
                        for s in outline
                    ]
                }
            }
            
        except Exception as e:
            yield {
                "type": EventType.ERROR.value,
                "message": f"âŒ Hata: {str(e)}",
                "error": str(e),
                "trace": traceback.format_exc()
            }
    
    def _create_bibliography(self, config: DeepScholarConfig) -> str:
        """Akademik kaynakÃ§a oluÅŸtur."""
        
        if not self.global_state.all_citations:
            return ""
        
        lang_headers = {
            DocumentLanguage.TURKISH: "KAYNAKÃ‡A",
            DocumentLanguage.ENGLISH: "REFERENCES",
            DocumentLanguage.GERMAN: "LITERATURVERZEICHNIS"
        }
        
        bibliography = f"\n\n---\n\n# ğŸ“š {lang_headers.get(config.language, 'KAYNAKÃ‡A')}\n\n"
        
        # Kaynak tipine gÃ¶re grupla
        web_sources = []
        academic_sources = []
        local_sources = []
        
        for citation in self.global_state.all_citations.values():
            if citation.source_type == "academic":
                academic_sources.append(citation)
            elif citation.source_type == "web":
                web_sources.append(citation)
            else:
                local_sources.append(citation)
        
        # Akademik kaynaklar
        if academic_sources:
            bibliography += "## Akademik Kaynaklar\n\n"
            for i, c in enumerate(academic_sources, 1):
                if config.citation_style == CitationStyle.APA:
                    bibliography += f"[{i}] {c.to_apa()}\n\n"
                elif config.citation_style == CitationStyle.IEEE:
                    bibliography += f"[{i}] {c.to_ieee()}\n\n"
                else:
                    bibliography += f"[{i}] {c.to_chicago()}\n\n"
        
        # Web kaynaklarÄ±
        if web_sources:
            bibliography += "## Web KaynaklarÄ±\n\n"
            for i, c in enumerate(web_sources, len(academic_sources) + 1):
                date = c.access_date or datetime.now().strftime("%Y-%m-%d")
                bibliography += f"[{i}] {c.title}. EriÅŸim: {c.url} ({date})\n\n"
        
        # Yerel kaynaklar
        if local_sources:
            bibliography += "## Yerel DÃ¶kÃ¼manlar\n\n"
            for i, c in enumerate(local_sources, len(academic_sources) + len(web_sources) + 1):
                bibliography += f"[{i}] {c.title}\n\n"
        
        return bibliography
    
    def _combine_content(
        self, 
        sections: List[Dict], 
        bibliography: str,
        config: DeepScholarConfig
    ) -> str:
        """TÃ¼m iÃ§eriÄŸi birleÅŸtir."""
        
        # BaÅŸlÄ±k sayfasÄ±
        lang_headers = {
            DocumentLanguage.TURKISH: {"title": "ARAÅTIRMA DÃ–KÃœMANI", "topic": "Konu", "date": "Tarih", "pages": "Sayfa"},
            DocumentLanguage.ENGLISH: {"title": "RESEARCH DOCUMENT", "topic": "Topic", "date": "Date", "pages": "Pages"},
            DocumentLanguage.GERMAN: {"title": "FORSCHUNGSDOKUMENT", "topic": "Thema", "date": "Datum", "pages": "Seiten"}
        }
        
        headers = lang_headers.get(config.language, lang_headers[DocumentLanguage.TURKISH])
        
        content = f"""# {config.title}

**{headers['topic']}:** {config.topic}
**{headers['date']}:** {datetime.now().strftime('%Y-%m-%d')}
**{headers['pages']}:** {config.page_count}

---

"""
        
        # Ä°Ã§indekiler
        content += "## ğŸ“‘ Ä°Ã‡Ä°NDEKÄ°LER\n\n"
        for section in sections:
            indent = "  " * (section.get("level", 1) - 1)
            content += f"{indent}- [{section['title']}](#{section['section_id']})\n"
        content += "\n---\n\n"
        
        # BÃ¶lÃ¼mler
        for section in sections:
            content += section['content'] + "\n\n---\n\n"
        
        # KaynakÃ§a
        content += bibliography
        
        return content
    
    def _integrate_visuals(self, content: str, visuals: List[Dict[str, Any]]) -> str:
        """GÃ¶rselleri iÃ§eriÄŸe entegre et."""
        if not visuals:
            return content
        
        visual_section = "\n\n---\n\n### ğŸ“Š GÃ¶rseller ve Diyagramlar\n\n"
        
        for visual in visuals:
            visual_type = visual.get("type", "")
            title = visual.get("title", "GÃ¶rsel")
            render_type = visual.get("render_type", "")
            
            visual_section += f"#### {title}\n\n"
            
            if render_type == "mermaid":
                code = visual.get("code", "")
                visual_section += f"```mermaid\n{code}\n```\n\n"
            
            elif render_type == "markdown":
                code = visual.get("code", "")
                visual_section += f"{code}\n\n"
            
            elif render_type == "latex":
                code = visual.get("code", "")
                visual_section += f"{code}\n\n"
            
            elif render_type == "code":
                code = visual.get("code", "")
                visual_section += f"{code}\n\n"
            
            elif render_type == "statistics":
                data = visual.get("data", {})
                stats = data.get("stats", [])
                highlight = data.get("highlight", "")
                
                if stats:
                    visual_section += "| Metrik | DeÄŸer | Trend |\n|--------|-------|-------|\n"
                    for stat in stats:
                        icon = stat.get("icon", "ğŸ“Š")
                        label = stat.get("label", "")
                        value = stat.get("value", "")
                        trend = stat.get("trend", "")
                        trend_icon = "ğŸ“ˆ" if trend == "up" else "ğŸ“‰" if trend == "down" else "â¡ï¸"
                        visual_section += f"| {icon} {label} | **{value}** | {trend_icon} |\n"
                    visual_section += "\n"
                
                if highlight:
                    visual_section += f"> ğŸ’¡ **Ã–nemli:** {highlight}\n\n"
            
            visual_section += "\n"
        
        # Ä°Ã§eriÄŸin sonuna ekle
        return content + visual_section


# ============================================================================
# PDF EXPORT
# ============================================================================

class PDFExporter:
    """PDF export iÅŸlemleri."""
    
    @staticmethod
    async def export_to_pdf(
        content: str,
        title: str,
        output_path: str
    ) -> bool:
        """Markdown iÃ§eriÄŸi PDF'e Ã§evir."""
        try:
            # WeasyPrint veya pdfkit kullan
            import markdown
            
            # Markdown -> HTML
            html_content = markdown.markdown(
                content,
                extensions=['tables', 'fenced_code', 'toc']
            )
            
            # HTML ÅŸablonu
            html_template = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Georgia', serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 40px;
        }}
        h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        h3 {{ color: #7f8c8d; }}
        code {{ background: #f4f4f4; padding: 2px 6px; border-radius: 3px; }}
        pre {{ background: #f4f4f4; padding: 15px; border-radius: 5px; overflow-x: auto; }}
        blockquote {{ border-left: 3px solid #3498db; margin-left: 0; padding-left: 20px; color: #555; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background: #f4f4f4; }}
    </style>
</head>
<body>
{html_content}
</body>
</html>
"""
            
            # PDF oluÅŸtur (pdfkit kullan)
            try:
                import pdfkit
                pdfkit.from_string(html_template, output_path)
                return True
            except ImportError:
                # Alternatif: HTML olarak kaydet
                html_path = output_path.replace('.pdf', '.html')
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(html_template)
                print(f"PDF export iÃ§in pdfkit gerekli. HTML olarak kaydedildi: {html_path}")
                return False
                
        except Exception as e:
            print(f"[PDF Export Error] {e}")
            return False


# ============================================================================
# SINGLETON
# ============================================================================

deep_scholar = DeepScholarOrchestrator()
